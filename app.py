"""
æ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ  - Streamlit UI
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from streamlit_plotly_events import plotly_events
import time
import os
import tempfile
from pathlib import Path
from typing import Dict, Any, Optional

from enhanced_speaker_recognition import JapaneseSpeakerRecognizer, RecognitionResult
from dataset_manager import DatasetManager
from manual_speaker_segmentation_v2 import ManualSpeakerSegmentatorV2
from segmentation_core import SegmentationConfig
from segmentation_core import AudioSegment

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'recognizer' not in st.session_state:
    st.session_state.recognizer = None
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'speakers_enrolled' not in st.session_state:
    st.session_state.speakers_enrolled = 0

# æ‰‹å‹•è©±è€…åˆ†é›¢ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'manual_segmentator' not in st.session_state:
    st.session_state.manual_segmentator = None
if 'manual_audio_loaded' not in st.session_state:
    st.session_state.manual_audio_loaded = False
if 'manual_segments' not in st.session_state:
    st.session_state.manual_segments = {}
if 'manual_segment_selection' not in st.session_state:
    st.session_state.manual_segment_selection = {'start': None, 'end': None}
if 'manual_show_jvs' not in st.session_state:
    st.session_state.manual_show_jvs = False
if 'manual_show_cv' not in st.session_state:
    st.session_state.manual_show_cv = False
if 'input_reset_counter' not in st.session_state:
    st.session_state.input_reset_counter = 0
if 'manual_segment_start_time' not in st.session_state:
    st.session_state.manual_segment_start_time = 0.0
if 'manual_segment_end_time' not in st.session_state:
    st.session_state.manual_segment_end_time = 0.0

# éŸ³å£°å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'audio_player_state' not in st.session_state:
    st.session_state.audio_player_state = {
        'is_playing': False,
        'current_position': 0.0,
        'play_start_time': 0.0,
        'play_end_time': None,
        'selection_start': None,
        'selection_end': None,
        'selection_mode': 'time_range',  # 'time_range', 'segment', 'full'
        'auto_play': True,
        'loop_play': False,
        'audio_file_path': None,
        'play_speed': 1.0,
        # Phase 1: å†ç”Ÿä½ç½®è¿½è·¡ç”¨ã®æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        'playback_start_timestamp': None,  # å†ç”Ÿé–‹å§‹æ™‚åˆ»ï¼ˆtime.time()ï¼‰
        'playback_paused_position': 0.0,   # ä¸€æ™‚åœæ­¢æ™‚ã®ä½ç½®
        'show_playback_position': True,    # å†ç”Ÿä½ç½®ç·šã®è¡¨ç¤ºãƒ•ãƒ©ã‚°
        'show_playback_range': True,       # å†ç”Ÿç¯„å›²ã®è¡¨ç¤ºãƒ•ãƒ©ã‚°
        'manual_position': None,           # æ‰‹å‹•è¨­å®šã•ã‚ŒãŸä½ç½®
        'last_update_time': None           # æœ€çµ‚æ›´æ–°æ™‚åˆ»
    }

# è¤‡æ•°è©±è€…åˆ†æç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'multi_recognizer' not in st.session_state:
    st.session_state.multi_recognizer = None
if 'diarization_initialized' not in st.session_state:
    st.session_state.diarization_initialized = False
if 'diarization_show_jvs' not in st.session_state:
    st.session_state.diarization_show_jvs = False
if 'diarization_show_cv' not in st.session_state:
    st.session_state.diarization_show_cv = False

# å˜ä¸€è©±è€…è­˜åˆ¥ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'show_jvs_in_results' not in st.session_state:
    st.session_state.show_jvs_in_results = False
if 'show_common_voice_in_results' not in st.session_state:
    st.session_state.show_common_voice_in_results = False

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    st.title("ğŸ¤ æ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("### SpeechBrain + ECAPA-TDNNã«ã‚ˆã‚‹é«˜ç²¾åº¦è©±è€…è­˜åˆ¥")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡
    setup_sidebar()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if st.session_state.model_loaded:
        display_main_content()
    else:
        display_welcome_page()

def setup_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š"""
    st.sidebar.header("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    if st.sidebar.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–", type="primary"):
        initialize_system()
    
    # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
    st.sidebar.subheader("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
    
    status_color = "ğŸŸ¢" if st.session_state.model_loaded else "ğŸ”´"
    st.sidebar.write(f"{status_color} ãƒ¢ãƒ‡ãƒ«: {'èª­ã¿è¾¼ã¿æ¸ˆã¿' if st.session_state.model_loaded else 'æœªèª­ã¿è¾¼ã¿'}")
    st.sidebar.write(f"ğŸ‘¥ ç™»éŒ²è©±è€…æ•°: {st.session_state.speakers_enrolled}")
    
    if st.session_state.model_loaded:
        
        # åŸ‹ã‚è¾¼ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
        st.sidebar.subheader("ğŸ’¾ åŸ‹ã‚è¾¼ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹è¡¨ç¤º
        if st.session_state.recognizer:
            cache_exists = os.path.exists("enrolled_speakers_embeddings.npz")
            cache_color = "ğŸŸ¢" if cache_exists else "ğŸ”´"
            st.sidebar.write(f"{cache_color} ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {'å­˜åœ¨' if cache_exists else 'æœªä½œæˆ'}")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ãƒœã‚¿ãƒ³
            col1, col2 = st.sidebar.columns(2)
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜") and st.session_state.recognizer.speaker_embeddings:
                    if st.session_state.recognizer.save_speaker_embeddings():
                        st.sidebar.success("âœ… ä¿å­˜å®Œäº†")
                    else:
                        st.sidebar.error("âŒ ä¿å­˜å¤±æ•—")
            
            with col2:
                if st.button("ğŸ—‘ï¸ å‰Šé™¤") and cache_exists:
                    try:
                        os.remove("enrolled_speakers_embeddings.npz")
                        st.sidebar.success("âœ… å‰Šé™¤å®Œäº†")
                        st.rerun()
                    except Exception as e:
                        st.sidebar.error(f"âŒ å‰Šé™¤å¤±æ•—: {e}")
        
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
        if st.sidebar.button("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"):
            show_system_info()

def initialize_system():
    """ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    with st.spinner("ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."):
        try:
            # RecognizeråˆæœŸåŒ–
            recognizer = JapaneseSpeakerRecognizer()
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            progress_bar.progress(25)
            
            if not recognizer.initialize_model():
                st.error("âŒ ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
            
            # è©±è€…ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
            status_text.text("è©±è€…ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­...")
            progress_bar.progress(50)
            
            enrolled_count = recognizer.build_speaker_database()
            
            # èƒŒæ™¯ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            status_text.text("èƒŒæ™¯ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...")
            progress_bar.progress(75)
            
            recognizer.build_background_model()
            
            # å®Œäº†
            progress_bar.progress(100)
            status_text.text("åˆæœŸåŒ–å®Œäº†ï¼")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹æ›´æ–°
            st.session_state.recognizer = recognizer
            st.session_state.model_loaded = True
            st.session_state.speakers_enrolled = enrolled_count
            
            st.success(f"âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†ï¼{enrolled_count}åã®è©±è€…ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
            time.sleep(1)
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")


def show_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®è¡¨ç¤º"""
    if st.session_state.recognizer is None:
        st.error("ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    info = st.session_state.recognizer.get_system_info()
    
    st.sidebar.subheader("ğŸ” è©³ç´°æƒ…å ±")
    for key, value in info.items():
        st.sidebar.write(f"**{key}**: {value}")

def display_welcome_page():
    """ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("""
        ## ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦
        
        ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**SpeechBrain**ã¨**ECAPA-TDNN**ã‚’ä½¿ç”¨ã—ãŸ
        é«˜ç²¾åº¦ãªæ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
        
        ### ğŸš€ ä¸»ãªæ©Ÿèƒ½
        
        - **é«˜ç²¾åº¦èªè­˜**: ECAPA-TDNNã«ã‚ˆã‚‹æœ€å…ˆç«¯ã®è©±è€…åŸ‹ã‚è¾¼ã¿
        - **èƒŒæ™¯è©±è€…é™¤å¤–**: JVSãƒ»Common Voiceè©±è€…ã®è‡ªå‹•é™¤å¤–
        - **ã‚¹ã‚³ã‚¢æ­£è¦åŒ–**: èƒŒæ™¯ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹èªè­˜ç²¾åº¦å‘ä¸Š
        - **ç›´æ„Ÿçš„UI**: Streamlitã«ã‚ˆã‚‹ä½¿ã„ã‚„ã™ã„ã‚¤ãƒ³ã‚¿ãƒ¼face
        
        ### ğŸ“‹ ä½¿ç”¨æ–¹æ³•
        
        1. **ã‚µã‚¤ãƒ‰ãƒãƒ¼**ã®ã€ŒğŸš€ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
        2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è©±è€…è­˜åˆ¥
        3. çµæœã¨ã‚¹ã‚³ã‚¢è©³ç´°ã‚’ç¢ºèª
        
        ### ğŸ“ ãƒ‡ãƒ¼ã‚¿æº–å‚™
        
        ```
        enroll/
        â”œâ”€â”€ yamada_taro/     # è©±è€…1ã®ãƒ•ã‚¡ã‚¤ãƒ«
        â”œâ”€â”€ sato_hanako/     # è©±è€…2ã®ãƒ•ã‚¡ã‚¤ãƒ«
        â””â”€â”€ tanaka_jiro/     # è©±è€…3ã®ãƒ•ã‚¡ã‚¤ãƒ«
        ```
        
        ---
        
        **æº–å‚™ãŒã§ããŸã‚‰ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ï¼**
        """)

def display_main_content():
    """ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¡¨ç¤º"""
    # ã‚¿ãƒ–è¨­å®š
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ¤ å˜ä¸€è©±è€…è­˜åˆ¥", 
        "ğŸ­ è¤‡æ•°è©±è€…åˆ†æ", 
        "ğŸ”Š æ‰‹å‹•è©±è€…åˆ†é›¢",
        "ğŸ‘¥ è©±è€…ç®¡ç†", 
        "ğŸ“Š çµ±è¨ˆæƒ…å ±"
    ])
    
    with tab1:
        display_recognition_tab()
    
    with tab2:
        display_diarization_tab()
    
    with tab3:
        display_manual_segmentation_tab()
    
    with tab4:
        display_speaker_management_tab()
    
    with tab5:
        display_statistics_tab()

def display_recognition_tab():
    """å˜ä¸€è©±è€…è­˜åˆ¥ã‚¿ãƒ–"""
    st.header("ğŸ¤ å˜ä¸€è©±è€…è­˜åˆ¥")
    st.caption("1åã®è©±è€…ã‚’ç™»éŒ²æ¸ˆã¿è©±è€…ã‹ã‚‰è­˜åˆ¥ã—ã¾ã™")
    
    if st.session_state.speakers_enrolled == 0:
        st.warning("âš ï¸ ç™»éŒ²ã•ã‚ŒãŸè©±è€…ãŒã„ã¾ã›ã‚“ã€‚enrollãƒ•ã‚©ãƒ«ãƒ€ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # è¡¨ç¤ºè¨­å®š
    st.subheader("ğŸ›ï¸ è¡¨ç¤ºè¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        show_jvs = st.checkbox(
            "ğŸ—¾ JVSè©±è€…ã‚’çµæœã«è¡¨ç¤º", 
            value=st.session_state.recognizer.config["ui"]["show_jvs_in_results"] if st.session_state.recognizer else True,
            help="èªè­˜çµæœã®ãƒˆãƒƒãƒ—10ã«JVSè©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
        )
    
    with col2:
        show_cv = st.checkbox(
            "ğŸŒ Common Voiceè©±è€…ã‚’çµæœã«è¡¨ç¤º",
            value=st.session_state.recognizer.config["ui"]["show_common_voice_in_results"] if st.session_state.recognizer else False,
            help="èªè­˜çµæœã®ãƒˆãƒƒãƒ—10ã«Common Voiceè©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
        )
    
    # è¨­å®šã‚’ä¸€æ™‚çš„ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    if 'show_jvs_in_results' not in st.session_state:
        st.session_state.show_jvs_in_results = show_jvs
    if 'show_common_voice_in_results' not in st.session_state:
        st.session_state.show_common_voice_in_results = show_cv
    
    # è¨­å®šãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
    if (st.session_state.show_jvs_in_results != show_jvs or 
        st.session_state.show_common_voice_in_results != show_cv):
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
        st.session_state.show_jvs_in_results = show_jvs
        st.session_state.show_common_voice_in_results = show_cv
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›´æ–°
        if st.session_state.recognizer:
            st.session_state.recognizer.config["ui"]["show_jvs_in_results"] = show_jvs
            st.session_state.recognizer.config["ui"]["show_common_voice_in_results"] = show_cv
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            try:
                import json
                with open("config.json", 'w', encoding='utf-8') as f:
                    json.dump(st.session_state.recognizer.config, f, indent=2, ensure_ascii=False)
            except Exception as e:
                st.error(f"è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        # å¤‰æ›´ãŒãªã„å ´åˆã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹ã ã‘
        st.session_state.show_jvs_in_results = show_jvs
        st.session_state.show_common_voice_in_results = show_cv
    
    st.divider()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['wav', 'mp3', 'flac', 'm4a', 'ogg'],
        help="å¯¾å¿œå½¢å¼: WAV, MP3, FLAC, M4A, OGG"
    )
    
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            # éŸ³å£°æƒ…å ±è¡¨ç¤º
            st.subheader("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {uploaded_file.name}")
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {uploaded_file.size / 1024:.1f} KB")
            
            with col2:
                # éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼
                st.audio(uploaded_file.getvalue())
            
            # è­˜åˆ¥å®Ÿè¡Œ
            if st.button("ğŸ” è©±è€…è­˜åˆ¥é–‹å§‹", type="primary"):
                perform_recognition(tmp_path)
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

def perform_recognition(audio_path: str):
    """è©±è€…è­˜åˆ¥ã®å®Ÿè¡Œ"""
    with st.spinner("éŸ³å£°ã‚’è§£æä¸­..."):
        try:
            # é€²æ—è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("éŸ³å£°ã‚’å‰å‡¦ç†ä¸­...")
            progress_bar.progress(25)
            
            # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
            status_text.text("è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡ºä¸­...")
            progress_bar.progress(50)
            
            result = st.session_state.recognizer.recognize_speaker(audio_path)
            
            status_text.text("ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ä¸­...")
            progress_bar.progress(75)
            
            if result is None:
                st.error("âŒ è©±è€…è­˜åˆ¥ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
            
            progress_bar.progress(100)
            status_text.text("è­˜åˆ¥å®Œäº†ï¼")
            
            # çµæœè¡¨ç¤º
            display_recognition_result(result)
            
        except Exception as e:
            st.error(f"âŒ è­˜åˆ¥ã‚¨ãƒ©ãƒ¼: {str(e)}")

def display_recognition_result(result: RecognitionResult):
    """èªè­˜çµæœã®è¡¨ç¤º"""
    st.subheader("ğŸ¯ è­˜åˆ¥çµæœ")
    
    # è¡¨ç¤ºè¨­å®šã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    show_jvs = getattr(st.session_state, 'show_jvs_in_results', True)
    show_cv = getattr(st.session_state, 'show_common_voice_in_results', False)
    
    # å…¨ã‚¹ã‚³ã‚¢ã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ã‚¹ã‚³ã‚¢ã‚’å–å¾—
    if result.all_scores:
        filtered_scores = st.session_state.recognizer.filter_scores_for_display(
            result.all_scores, show_jvs, show_cv
        )
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®æœ€ä¸Šä½è©±è€…ã‚’æ±ºå®š
        filtered_best_speaker = None
        filtered_best_score = None
        if filtered_scores:
            filtered_best_speaker = max(filtered_scores, key=filtered_scores.get)
            filtered_best_score = filtered_scores[filtered_best_speaker]
    else:
        filtered_scores = {}
        filtered_best_speaker = None
        filtered_best_score = None
    
    # è¡¨ç¤ºã™ã‚‹è©±è€…ã¨ä¿¡é ¼åº¦ã‚’æ±ºå®š
    display_speaker = result.speaker_id
    display_confidence = result.confidence
    display_raw_score = result.raw_score
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°è¨­å®šã§ã‚ªãƒªã‚¸ãƒŠãƒ«ã®æœ€ä¸Šä½è©±è€…ãŒé™¤å¤–ã•ã‚Œã‚‹å ´åˆ
    if filtered_best_speaker and filtered_best_speaker != result.speaker_id:
        # JVSè©±è€…ãŒé™¤å¤–ã•ã‚Œã‚‹å ´åˆã®åˆ¤å®š
        is_original_jvs = st.session_state.recognizer.dataset_manager.is_jvs_speaker(result.speaker_id)
        is_original_cv = st.session_state.recognizer.dataset_manager.is_common_voice_speaker(result.speaker_id)
        
        if (is_original_jvs and not show_jvs) or (is_original_cv and not show_cv):
            display_speaker = filtered_best_speaker
            display_raw_score = filtered_best_score
            # ä¿¡é ¼åº¦ã¯åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã§è¨ˆç®—ï¼ˆç°¡ç•¥åŒ–ï¼‰
            display_confidence = filtered_best_score
    
    # ãƒ¡ã‚¤ãƒ³çµæœ
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="è­˜åˆ¥ã•ã‚ŒãŸè©±è€…",
            value=display_speaker,
            delta=None
        )
    
    with col2:
        confidence_color = "ğŸŸ¢" if display_confidence > 0.5 else "ğŸŸ¡" if display_confidence > 0.25 else "ğŸ”´"
        st.metric(
            label="ä¿¡é ¼åº¦",
            value=f"{display_confidence:.3f}",
            delta=confidence_color
        )
    
    with col3:
        st.metric(
            label="ç”Ÿã‚¹ã‚³ã‚¢",
            value=f"{display_raw_score:.3f}"
        )
    
    # ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯
    threshold = st.session_state.recognizer.threshold
    if display_confidence > threshold:
        st.success(f"âœ… ä¿¡é ¼åº¦ãŒã—ãã„å€¤({threshold:.3f})ã‚’ä¸Šå›ã‚Šã¾ã—ãŸ")
    else:
        st.warning(f"âš ï¸ ä¿¡é ¼åº¦ãŒã—ãã„å€¤({threshold:.3f})ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ")
    
    # è©³ç´°ã‚¹ã‚³ã‚¢è¡¨ç¤ºï¼ˆãƒˆãƒƒãƒ—10ï¼‰
    if filtered_scores:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10è©±è€…ã‚¹ã‚³ã‚¢")
        filter_info = []
        if not show_jvs:
            filter_info.append("JVSè©±è€…ã‚’é™¤å¤–")
        if not show_cv:
            filter_info.append("Common Voiceè©±è€…ã‚’é™¤å¤–")
        
        caption = f"ä¸Šä½{len(filtered_scores)}åã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢"
        if filter_info:
            caption += f" ({', '.join(filter_info)})"
        st.caption(caption)
        
        display_score_chart(filtered_scores, display_speaker)
    
    # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢æƒ…å ±
    if result.normalized_score is not None:
        st.subheader("ğŸ”§ ã‚¹ã‚³ã‚¢æ­£è¦åŒ–æƒ…å ±")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**æ­£è¦åŒ–å‰**: {result.raw_score:.3f}")
            st.write(f"**æ­£è¦åŒ–å¾Œ**: {result.normalized_score:.3f}")
        
        with col2:
            improvement = result.normalized_score - result.raw_score
            improvement_color = "ğŸŸ¢" if improvement > 0 else "ğŸ”´"
            st.write(f"**æ”¹å–„åº¦**: {improvement_color} {improvement:+.3f}")

def display_score_chart(scores: Dict[str, float], best_speaker: str):
    """ã‚¹ã‚³ã‚¢ãƒãƒ£ãƒ¼ãƒˆã®è¡¨ç¤º"""
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    speakers = list(scores.keys())
    score_values = list(scores.values())
    colors = ['red' if speaker == best_speaker else 'lightblue' for speaker in speakers]
    
    # æ¨ªæ£’ã‚°ãƒ©ãƒ•
    fig = go.Figure(data=[
        go.Bar(
            y=speakers,
            x=score_values,
            orientation='h',
            marker_color=colors,
            text=[f"{score:.3f}" for score in score_values],
            textposition='auto'
        )
    ])
    
    fig.update_layout(
        title="è©±è€…åˆ¥é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢",
        xaxis_title="é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢",
        yaxis_title="è©±è€…ID",
        height=max(300, len(speakers) * 40),
        showlegend=False
    )
    
    st.plotly_chart(fig, use_container_width=True)

def display_speaker_management_tab():
    """è©±è€…ç®¡ç†ã‚¿ãƒ–"""
    st.header("ğŸ‘¥ è©±è€…ç®¡ç†")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†
    dataset_manager = DatasetManager()
    
    # çµ±è¨ˆæƒ…å ±
    stats = dataset_manager.get_speaker_statistics("enroll")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·è©±è€…æ•°", stats["total_speakers"])
    
    with col2:
        st.metric("æœ‰åŠ¹è©±è€…æ•°", stats["valid_speakers"])
    
    with col3:
        st.metric("é™¤å¤–è©±è€…æ•°", stats["excluded_speakers"])
    
    with col4:
        st.metric("éŸ³å£°ãªã—è©±è€…æ•°", stats["speakers_with_no_audio"])
    
    # è©±è€…ãƒªã‚¹ãƒˆè¡¨ç¤º
    if os.path.exists("enroll"):
        st.subheader("ğŸ“‹ è©±è€…ä¸€è¦§")
        
        speaker_data = []
        for speaker_id in os.listdir("enroll"):
            speaker_path = os.path.join("enroll", speaker_id)
            if not os.path.isdir(speaker_path):
                continue
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            audio_files = dataset_manager._get_audio_files(speaker_path)
            
            # çŠ¶æ…‹åˆ¤å®š
            if dataset_manager.should_exclude_speaker(speaker_id):
                status = "âŒ é™¤å¤–"
                reason = "èƒŒæ™¯è©±è€…"
            elif not audio_files:
                status = "âš ï¸ éŸ³å£°ãªã—"
                reason = "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãªã—"
            else:
                status = "âœ… æœ‰åŠ¹"
                reason = "ç™»éŒ²å¯èƒ½"
            
            speaker_data.append({
                "è©±è€…ID": speaker_id,
                "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°": len(audio_files),
                "çŠ¶æ…‹": status,
                "ç†ç”±": reason
            })
        
        if speaker_data:
            df = pd.DataFrame(speaker_data)
            st.dataframe(df, use_container_width=True)
        else:
            st.info("ğŸ“ enrollãƒ•ã‚©ãƒ«ãƒ€ã«è©±è€…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # èƒŒæ™¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±
    st.subheader("ğŸ—‚ï¸ èƒŒæ™¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±")
    bg_info = dataset_manager.get_background_dataset_info()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**JVSè©±è€…æ•°**: {bg_info['jvs_speakers_count']}")
        st.write(f"**é™¤å¤–è¨­å®š**: {'æœ‰åŠ¹' if bg_info['exclusion_enabled'] else 'ç„¡åŠ¹'}")
    
    with col2:
        st.write(f"**Common Voiceãƒ‘ã‚¿ãƒ¼ãƒ³**: {', '.join(bg_info['common_voice_patterns'])}")

def display_statistics_tab():
    """çµ±è¨ˆæƒ…å ±ã‚¿ãƒ–"""
    st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±")
    
    if st.session_state.recognizer is None:
        st.warning("ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    info = st.session_state.recognizer.get_system_info()
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ç™»éŒ²è©±è€…æ•°", info["enrolled_speakers"])
        st.metric("ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ", f"{info['sample_rate']} Hz")
    
    with col2:
        st.metric("èƒŒæ™¯ã‚µãƒ³ãƒ—ãƒ«æ•°", info["background_samples"])
        st.metric("ã—ãã„å€¤", f"{info['threshold']:.3f}")
    
    with col3:
        st.metric("ãƒ‡ãƒã‚¤ã‚¹", info["device"])
        st.metric("ã‚¹ã‚³ã‚¢æ­£è¦åŒ–", "æœ‰åŠ¹" if info["score_normalization"] else "ç„¡åŠ¹")
    
    # è©³ç´°æƒ…å ±
    st.subheader("ğŸ”§ è©³ç´°è¨­å®š")
    
    details_data = {
        "é …ç›®": [
            "ãƒ¢ãƒ‡ãƒ«å",
            "æœ€å°éŸ³å£°é•·",
            "æœ€å¤§éŸ³å£°é•·",
            "ãƒ‡ãƒã‚¤ã‚¹",
            "ã‚¹ã‚³ã‚¢æ­£è¦åŒ–",
            "èƒŒæ™¯ã‚µãƒ³ãƒ—ãƒ«æ•°"
        ],
        "å€¤": [
            info["model_name"],
            f"{info['min_duration']} ç§’",
            f"{info['max_duration']} ç§’",
            info["device"],
            "æœ‰åŠ¹" if info["score_normalization"] else "ç„¡åŠ¹",
            f"{info['background_samples']} ã‚µãƒ³ãƒ—ãƒ«"
        ]
    }
    
    details_df = pd.DataFrame(details_data)
    st.dataframe(details_df, use_container_width=True, hide_index=True)
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
    st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±")
    
    if info["device"] == "cuda":
        st.success("ğŸš€ GPUåŠ é€ŸãŒæœ‰åŠ¹ã§ã™")
    elif info["device"] == "mps":
        st.success("ğŸ Apple Silicon GPUåŠ é€ŸãŒæœ‰åŠ¹ã§ã™")
    else:
        st.info("ğŸ’» CPUå‡¦ç†ã§å‹•ä½œä¸­ã§ã™")

def display_diarization_tab():
    """è¤‡æ•°è©±è€…åˆ†æã‚¿ãƒ–"""
    st.header("ğŸ­ è¤‡æ•°è©±è€…åˆ†æ")
    st.caption("è¤‡æ•°è©±è€…ã®éŸ³å£°ã‹ã‚‰æ™‚ç³»åˆ—ã§ã®è©±è€…èªè­˜ã‚’è¡Œã„ã¾ã™")
    
    # åˆæœŸåŒ–ç¢ºèªã¯æ—¢ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§å®Ÿè¡Œæ¸ˆã¿
    
    # åˆæœŸåŒ–ãƒœã‚¿ãƒ³
    if not st.session_state.diarization_initialized:
        if st.button("ğŸš€ è¤‡æ•°è©±è€…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–", type="primary"):
            initialize_diarization_system()
        
        st.info("""
        ğŸ’¡ **è¤‡æ•°è©±è€…åˆ†æã«ã¤ã„ã¦**
        
        ã“ã®ã‚¿ãƒ–ã§ã¯ã€è¤‡æ•°ã®è©±è€…ãŒåŒæ™‚ã«è©±ã—ã¦ã„ã‚‹éŸ³å£°ã‚’åˆ†æã—ã€ä»¥ä¸‹ã‚’è¡Œã„ã¾ã™ï¼š
        
        ğŸ“Š **ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³**: ã€Œã„ã¤èª°ãŒè©±ã—ã¦ã„ã‚‹ã‹ã€ã‚’æ¤œå‡º
        ğŸ¯ **è©±è€…è­˜åˆ¥**: å„æ™‚é–“å¸¯ã®è©±è€…ã‚’ç™»éŒ²æ¸ˆã¿è©±è€…ã‹ã‚‰ç‰¹å®š
        
        **å¿…è¦ãªæº–å‚™**:
        - Hugging Face Token ãŒ `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šæ¸ˆã¿
        - pyannote.audio ã®åˆ©ç”¨è¦ç´„ã«åŒæ„æ¸ˆã¿
        """)
        return
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "è¤‡æ•°è©±è€…ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['wav', 'mp3', 'flac', 'm4a', 'ogg'],
        help="2åä»¥ä¸Šã®è©±è€…ãŒå«ã¾ã‚Œã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«"
    )
    
    if uploaded_file:
        # è¨­å®š
        st.subheader("âš™ï¸ åˆ†æè¨­å®š")
        
        # è©±è€…æ•°è¨­å®š
        col1, col2 = st.columns(2)
        with col1:
            min_speakers = st.number_input("æœ€å°è©±è€…æ•°", 1, 10, 1, help="éŸ³å£°ã«å«ã¾ã‚Œã‚‹æœ€å°è©±è€…æ•°")
        with col2:
            max_speakers = st.number_input("æœ€å¤§è©±è€…æ•°", 1, 10, 5, help="éŸ³å£°ã«å«ã¾ã‚Œã‚‹æœ€å¤§è©±è€…æ•°")
        
        # è¡¨ç¤ºè¨­å®š
        st.write("**èªè­˜çµæœã®è¡¨ç¤ºè¨­å®š**")
        col1, col2 = st.columns(2)
        
        with col1:
            show_jvs = st.checkbox(
                "ğŸ—¾ JVSè©±è€…ã‚’çµæœã«è¡¨ç¤º", 
                value=st.session_state.diarization_show_jvs,
                help="èªè­˜çµæœã«JVS (Japanese Versatile Speech) ã‚³ãƒ¼ãƒ‘ã‚¹ã®è©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
            )
            st.session_state.diarization_show_jvs = show_jvs
        
        with col2:
            show_cv = st.checkbox(
                "ğŸŒ Common Voiceè©±è€…ã‚’çµæœã«è¡¨ç¤º",
                value=st.session_state.diarization_show_cv,
                help="èªè­˜çµæœã«Mozilla Common Voiceã®è©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
            )
            st.session_state.diarization_show_cv = show_cv
        
        # éŸ³å£°æƒ…å ±è¡¨ç¤º
        st.subheader("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {uploaded_file.name}")
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {uploaded_file.size / 1024:.1f} KB")
        
        with col2:
            # éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼
            st.audio(uploaded_file.getvalue())
        
        # åˆ†æå®Ÿè¡Œ
        if st.button("ğŸ­ è¤‡æ•°è©±è€…åˆ†æé–‹å§‹", type="primary"):
            perform_multi_speaker_analysis(uploaded_file, min_speakers, max_speakers, show_jvs, show_cv)

def initialize_diarization_system():
    """è¤‡æ•°è©±è€…åˆ†æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
    with st.spinner("è¤‡æ•°è©±è€…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."):
        try:
            # é€²æ—è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            progress_bar.progress(25)
            
            from speaker_diarization import MultiSpeakerRecognizer
            
            status_text.text("ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
            progress_bar.progress(50)
            
            recognizer = MultiSpeakerRecognizer()
            
            status_text.text("è©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆä¸­...")
            progress_bar.progress(75)
            
            if recognizer.initialize():
                st.session_state.multi_recognizer = recognizer
                st.session_state.diarization_initialized = True
                
                progress_bar.progress(100)
                status_text.text("åˆæœŸåŒ–å®Œäº†ï¼")
                
                st.success("âœ… è¤‡æ•°è©±è€…åˆ†æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
                time.sleep(1)
                st.rerun()
            else:
                st.error("âŒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                
        except Exception as e:
            st.error(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            st.info("ğŸ’¡ Hugging Face Token ã®è¨­å®šã‚„ pyannote.audio ã®åˆ©ç”¨è¦ç´„åŒæ„ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

def perform_multi_speaker_analysis(uploaded_file, min_speakers, max_speakers, show_jvs=True, show_cv=False):
    """è¤‡æ•°è©±è€…åˆ†æå®Ÿè¡Œ"""
    with st.spinner("è¤‡æ•°è©±è€…åˆ†æä¸­..."):
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        
        try:
            # é€²æ—è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
            progress_bar.progress(30)
            
            # åˆ†æå®Ÿè¡Œ
            result = st.session_state.multi_recognizer.process_audio(
                tmp_path, min_speakers, max_speakers
            )
            
            status_text.text("è©±è€…èªè­˜å®Ÿè¡Œä¸­...")
            progress_bar.progress(70)
            
            progress_bar.progress(100)
            status_text.text("åˆ†æå®Œäº†ï¼")
            
            # çµæœè¡¨ç¤º
            display_multi_speaker_result(result, show_jvs, show_cv)
            
        except Exception as e:
            st.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

def display_multi_speaker_result(result, show_jvs=True, show_cv=False):
    """è¤‡æ•°è©±è€…åˆ†æçµæœè¡¨ç¤º"""
    st.subheader("ğŸ¯ åˆ†æçµæœ")
    
    # ã‚µãƒãƒªãƒ¼
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ¤œå‡ºè©±è€…æ•°", result.total_speakers)
    with col2:
        st.metric("ç·æ™‚é–“", f"{result.total_duration:.1f}ç§’")
    with col3:
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ã‚‚è¡¨ç¤º
        if len(result.segments) > 0:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°è¨ˆç®—
            filtered_count = 0
            for segment in result.segments:
                speaker = segment['recognized_speaker']
                if speaker.startswith('jvs') and not show_jvs:
                    continue
                if (speaker.startswith('cv_') or speaker.startswith('commonvoice_')) and not show_cv:
                    continue
                filtered_count += 1
            
            if filtered_count != len(result.segments):
                st.metric("è¡¨ç¤ºã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°", f"{filtered_count}/{len(result.segments)}")
            else:
                st.metric("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°", len(result.segments))
        else:
            st.metric("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°", 0)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°
    if result.segments:
        # JVS/Common Voiceè©±è€…ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_segments = []
        for segment in result.segments:
            speaker = segment['recognized_speaker']
            
            # JVSè©±è€…ã®ãƒã‚§ãƒƒã‚¯
            if speaker.startswith('jvs') and not show_jvs:
                continue
            
            # Common Voiceè©±è€…ã®ãƒã‚§ãƒƒã‚¯  
            if (speaker.startswith('cv_') or speaker.startswith('commonvoice_')) and not show_cv:
                continue
            
            filtered_segments.append(segment)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æƒ…å ±ã®è¡¨ç¤º
        filter_info = []
        if not show_jvs:
            filter_info.append("JVSè©±è€…ã‚’é™¤å¤–")
        if not show_cv:
            filter_info.append("Common Voiceè©±è€…ã‚’é™¤å¤–")
        
        if filter_info:
            st.caption(f"è¡¨ç¤ºè¨­å®š: {', '.join(filter_info)}")
        
        st.subheader("ğŸ“‹ æ™‚ç³»åˆ—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
        
        if not filtered_segments:
            st.warning("âš ï¸ è¡¨ç¤ºè¨­å®šã«ã‚ˆã‚Šã€ã™ã¹ã¦ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒé™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚è¡¨ç¤ºè¨­å®šã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
            return
        
        for i, segment in enumerate(filtered_segments):
            # èªè­˜æˆåŠŸã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ç·‘ã€å¤±æ•—ã¯èµ¤ã§è¡¨ç¤º
            if segment['recognized_speaker'] != "æœªèªè­˜":
                status_color = "ğŸŸ¢"
                confidence_text = f" (ä¿¡é ¼åº¦: {segment['confidence']:.3f})" if segment['confidence'] is not None else " (ä¿¡é ¼åº¦: N/A)"
            else:
                status_color = "ğŸ”´"
                confidence_text = ""
            
            with st.expander(
                f"{status_color} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment['segment_id']}: "
                f"{segment['start_time']:.1f}s - {segment['end_time']:.1f}s "
                f"â†’ {segment['recognized_speaker']}{confidence_text}"
            ):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**é–‹å§‹æ™‚é–“**: {segment['start_time']:.1f}ç§’")
                    st.write(f"**çµ‚äº†æ™‚é–“**: {segment['end_time']:.1f}ç§’")
                    st.write(f"**æ™‚é–“é•·**: {segment['duration']:.1f}ç§’")
                with col2:
                    st.write(f"**ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«**: {segment['diarization_label']}")
                    st.write(f"**èªè­˜è©±è€…**: {segment['recognized_speaker']}")
                    if segment['confidence'] > 0:
                        confidence_value = segment['confidence']
                        st.write(f"**ä¿¡é ¼åº¦**: {confidence_value:.3f}" if confidence_value is not None else "**ä¿¡é ¼åº¦**: N/A")
                
                # ãƒˆãƒƒãƒ—5è©±è€…ã‚¹ã‚³ã‚¢è¡¨ç¤º
                if 'all_scores' in segment and segment['all_scores']:
                    display_segment_top5_scores(segment, show_jvs, show_cv)
        
        # ğŸ“Š è¦–è¦šåŒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("ğŸ“Š è¦–è¦šåŒ–")
        
        # ã‚¿ãƒ–æ§‹æˆ
        tab1, tab2 = st.tabs([
            "â° ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³", 
            "ğŸ‘¥ è©±è€…åˆ¥ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³"
        ])
        
        with tab1:
            st.caption("pyannote.audioã«ã‚ˆã‚‹è©±è€…åˆ†é›¢çµæœ")
            display_diarization_timeline_chart(filtered_segments)
        
        with tab2:
            st.caption("è©±è€…èªè­˜çµæœãƒ™ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ + çµ±è¨ˆ")
            display_speaker_summary_with_timeline(filtered_segments)
    
    else:
        st.warning("âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚„è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def display_diarization_timeline_chart(segments):
    """ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º"""
    import plotly.graph_objects as go
    import plotly.colors as pc
    
    if not segments:
        st.warning("è¡¨ç¤ºã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã¨è‰²ã®å‰²ã‚Šå½“ã¦
    diarization_labels = list(set([s['diarization_label'] for s in segments]))
    diarization_labels.sort()  # ä¸€è²«ã—ãŸé †åº
    colors = pc.qualitative.Set3[:len(diarization_labels)]
    label_colors = dict(zip(diarization_labels, colors))
    
    fig = go.Figure()
    
    # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’Ganttãƒãƒ£ãƒ¼ãƒˆã¨ã—ã¦è¿½åŠ 
    for segment in segments:
        diarization_label = segment['diarization_label']
        
        # ãƒ›ãƒãƒ¼æƒ…å ±
        hover_text = (
            f"ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«: {diarization_label}<br>"
            f"èªè­˜è©±è€…: {segment['recognized_speaker']}<br>"
            f"æ™‚é–“: {segment['start_time']:.1f}s - {segment['end_time']:.1f}s<br>"
            f"æ™‚é–“é•·: {segment['duration']:.1f}s<br>"
            f"ä¿¡é ¼åº¦: {format(segment['confidence'], '.3f') if segment['confidence'] is not None else 'N/A'}"
        )
        
        fig.add_trace(go.Bar(
            x=[segment['duration']],
            y=[diarization_label],
            base=segment['start_time'],
            orientation='h',
            name=f"{diarization_label} â†’ {segment['recognized_speaker']}",
            marker_color=label_colors[diarization_label],
            hovertemplate=hover_text + "<extra></extra>",
            showlegend=False
        ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
    fig.update_layout(
        title="â° ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
        xaxis_title="æ™‚é–“ï¼ˆç§’ï¼‰",
        yaxis_title="ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«",
        height=max(300, len(diarization_labels) * 60),
        showlegend=False,
        barmode='overlay'
    )
    
    st.plotly_chart(fig, use_container_width=True)

def display_speaker_summary_with_timeline(segments):
    """è©±è€…åˆ¥ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ + çµ±è¨ˆæƒ…å ±ã®çµ±åˆè¡¨ç¤º"""
    import plotly.graph_objects as go
    import plotly.colors as pc
    
    if not segments:
        st.warning("è¡¨ç¤ºã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # è©±è€…åˆ¥ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
    speakers = list(set([s['recognized_speaker'] for s in segments]))
    speakers.sort()  # ä¸€è²«ã—ãŸé †åº
    colors = pc.qualitative.Set2[:len(speakers)]
    speaker_colors = dict(zip(speakers, colors))
    
    fig = go.Figure()
    
    # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’Ganttãƒãƒ£ãƒ¼ãƒˆã¨ã—ã¦è¿½åŠ 
    for segment in segments:
        speaker = segment['recognized_speaker']
        
        # ãƒ›ãƒãƒ¼æƒ…å ±
        hover_text = (
            f"èªè­˜è©±è€…: {speaker}<br>"
            f"æ™‚é–“: {segment['start_time']:.1f}s - {segment['end_time']:.1f}s<br>"
            f"æ™‚é–“é•·: {segment['duration']:.1f}s<br>"
            f"ä¿¡é ¼åº¦: {format(segment['confidence'], '.3f') if segment['confidence'] is not None else 'N/A'}<br>"
            f"å…ƒãƒ©ãƒ™ãƒ«: {segment['diarization_label']}"
        )
        
        fig.add_trace(go.Bar(
            x=[segment['duration']],
            y=[speaker],
            base=segment['start_time'],
            orientation='h',
            name=speaker,
            marker_color=speaker_colors[speaker],
            hovertemplate=hover_text + "<extra></extra>",
            showlegend=False
        ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
    fig.update_layout(
        title="ğŸ‘¥ è©±è€…åˆ¥ç™ºè©±ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
        xaxis_title="æ™‚é–“ï¼ˆç§’ï¼‰",
        yaxis_title="èªè­˜è©±è€…",
        height=max(300, len(speakers) * 60),
        showlegend=False,
        barmode='overlay'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ãƒ»è¡¨ç¤º
    speaker_stats = calculate_speaker_statistics(segments)
    display_speaker_statistics_table(speaker_stats, speaker_colors, segments)

def calculate_speaker_statistics(segments):
    """è©±è€…åˆ¥çµ±è¨ˆè¨ˆç®—"""
    speaker_stats = {}
    
    for segment in segments:
        speaker = segment['recognized_speaker']
        if speaker not in speaker_stats:
            speaker_stats[speaker] = {
                'segments': 0,
                'total_time': 0.0,
                'total_confidence': 0.0,
                'avg_confidence': 0.0
            }
        
        speaker_stats[speaker]['segments'] += 1
        speaker_stats[speaker]['total_time'] += segment['duration']
        if segment['confidence'] > 0:
            speaker_stats[speaker]['total_confidence'] += segment['confidence']
    
    # å¹³å‡ä¿¡é ¼åº¦è¨ˆç®—
    for speaker in speaker_stats:
        if speaker_stats[speaker]['segments'] > 0:
            speaker_stats[speaker]['avg_confidence'] = (
                speaker_stats[speaker]['total_confidence'] / 
                speaker_stats[speaker]['segments']
            )
    
    return speaker_stats

def display_speaker_statistics_table(speaker_stats, speaker_colors, segments):
    """è©±è€…åˆ¥çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"""
    st.subheader("ğŸ“Š è©±è€…åˆ¥çµ±è¨ˆ")
    
    if not speaker_stats:
        st.warning("è¡¨ç¤ºã™ã‚‹çµ±è¨ˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # åˆè¨ˆæ™‚é–“è¨ˆç®—
    total_time = sum([s['duration'] for s in segments])
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼
    cols = st.columns([3, 1, 1, 1, 1])
    with cols[0]:
        st.write("**è©±è€…**")
    with cols[1]:
        st.write("**ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°**")
    with cols[2]:
        st.write("**åˆè¨ˆæ™‚é–“**")
    with cols[3]:
        st.write("**æ™‚é–“å‰²åˆ**")
    with cols[4]:
        st.write("**å¹³å‡ä¿¡é ¼åº¦**")
    
    st.divider()
    
    # å„è©±è€…ã®çµ±è¨ˆã‚’åˆè¨ˆæ™‚é–“é †ã§è¡¨ç¤º
    sorted_speakers = sorted(
        speaker_stats.items(), 
        key=lambda x: x[1]['total_time'], 
        reverse=True
    )
    
    for speaker, stats in sorted_speakers:
        time_ratio = (stats['total_time'] / total_time * 100) if total_time > 0 else 0
        
        cols = st.columns([3, 1, 1, 1, 1])
        with cols[0]:
            # è©±è€…åã«è‰²ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ä»˜ã
            color = speaker_colors.get(speaker, "#888888")
            st.markdown(f'<span style="color: {color};">â—</span> **{speaker}**', unsafe_allow_html=True)
        with cols[1]:
            st.write(f"{stats['segments']}")
        with cols[2]:
            st.write(f"{stats['total_time']:.1f}ç§’")
        with cols[3]:
            st.write(f"{time_ratio:.1f}%")
        with cols[4]:
            if stats['avg_confidence'] > 0:
                st.write(f"{stats['avg_confidence']:.3f}")
            else:
                st.write("N/A")

def display_segment_top5_scores(segment, show_jvs=True, show_cv=False):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒˆãƒƒãƒ—5è©±è€…ã‚¹ã‚³ã‚¢è¡¨ç¤º"""
    all_scores = segment['all_scores']
    
    if not all_scores:
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
    filtered_scores = {}
    for speaker, score in all_scores.items():
        # JVSè©±è€…ã®ãƒã‚§ãƒƒã‚¯
        if speaker.startswith('jvs') and not show_jvs:
            continue
        
        # Common Voiceè©±è€…ã®ãƒã‚§ãƒƒã‚¯  
        if (speaker.startswith('cv_') or speaker.startswith('commonvoice_')) and not show_cv:
            continue
        
        filtered_scores[speaker] = score
    
    if not filtered_scores:
        return
    
    # ãƒˆãƒƒãƒ—5ã‚’å–å¾—
    sorted_scores = sorted(filtered_scores.items(), key=lambda x: x[1], reverse=True)
    top5_scores = sorted_scores[:5]
    
    st.divider()
    st.write("**ğŸ† ãƒˆãƒƒãƒ—5è©±è€…ã‚¹ã‚³ã‚¢**")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æƒ…å ±
    filter_info = []
    if not show_jvs:
        filter_info.append("JVSè©±è€…ã‚’é™¤å¤–")
    if not show_cv:
        filter_info.append("Common Voiceè©±è€…ã‚’é™¤å¤–")
    
    if filter_info:
        st.caption(f"è¡¨ç¤ºè¨­å®š: {', '.join(filter_info)}")
    
    # ã‚¹ã‚³ã‚¢è¡¨ç¤º
    for i, (speaker, score) in enumerate(top5_scores):
        rank = i + 1
        
        # 1ä½ã¯å¤ªå­—ã€èªè­˜ã•ã‚ŒãŸè©±è€…ã¯èƒŒæ™¯è‰²ä»˜ã
        if speaker == segment['recognized_speaker']:
            st.markdown(f"**{rank}. ğŸ¥‡ {speaker}**: `{score:.3f}` â† **èªè­˜çµæœ**")
        elif rank == 1:
            st.markdown(f"**{rank}. {speaker}**: **`{score:.3f}`**")
        else:
            medal = "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else f"{rank}."
            st.write(f"{medal} {speaker}: `{score:.3f}`")
    
    # è¡¨ç¤ºã•ã‚ŒãŸçµæœæ•°ã‚’è¡¨ç¤º
    if len(filtered_scores) > 5:
        st.caption(f"ä»– {len(filtered_scores) - 5} åã®å€™è£œ")

def display_manual_segmentation_tab():
    """æ‰‹å‹•è©±è€…åˆ†é›¢ã‚¿ãƒ–"""
    st.header("ğŸ”Š æ‰‹å‹•è©±è€…åˆ†é›¢")
    st.caption("éŸ³å£°æ³¢å½¢ã‚’è¦‹ãªãŒã‚‰æ‰‹å‹•ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã€è©±è€…è­˜åˆ¥ã‚’è¡Œã„ã¾ã™")
    
    if st.session_state.speakers_enrolled == 0:
        st.warning("âš ï¸ ç™»éŒ²ã•ã‚ŒãŸè©±è€…ãŒã„ã¾ã›ã‚“ã€‚enrollãƒ•ã‚©ãƒ«ãƒ€ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # JVS/Common Voiceè¡¨ç¤ºè¨­å®š
    st.subheader("ğŸ›ï¸ èªè­˜è¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        show_jvs = st.checkbox(
            "ğŸ—¾ JVSè©±è€…ã‚’çµæœã«è¡¨ç¤º",
            value=st.session_state.recognizer.config["ui"]["show_jvs_in_results"] if st.session_state.recognizer else False,
            help="èªè­˜çµæœã®Top-5å€™è£œã«JVSè©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
        )
    
    with col2:
        show_cv = st.checkbox(
            "ğŸŒ Common Voiceè©±è€…ã‚’çµæœã«è¡¨ç¤º",
            value=st.session_state.recognizer.config["ui"]["show_common_voice_in_results"] if st.session_state.recognizer else False,
            help="èªè­˜çµæœã®Top-5å€™è£œã«Common Voiceè©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
        )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    if 'manual_show_jvs' not in st.session_state:
        st.session_state.manual_show_jvs = show_jvs
    if 'manual_show_cv' not in st.session_state:
        st.session_state.manual_show_cv = show_cv
    
    st.session_state.manual_show_jvs = show_jvs
    st.session_state.manual_show_cv = show_cv
    
    # Step 1: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ“ Step 1: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['wav', 'mp3', 'flac', 'm4a', 'ogg'],
        key="manual_audio_upload"
    )
    
    if uploaded_file:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        if st.session_state.manual_segmentator is None:
            if st.session_state.recognizer:
                # è¨­å®šã®åˆæœŸåŒ–
                config = SegmentationConfig()
                st.session_state.manual_segmentator = ManualSpeakerSegmentatorV2(st.session_state.recognizer, config)
            else:
                st.error("ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
                return
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        if not st.session_state.manual_audio_loaded:
            try:
                file_extension = uploaded_file.name.split('.')[-1].lower()
                if file_extension not in ['wav', 'mp3', 'flac', 'm4a', 'ogg']:
                    st.error(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_extension}")
                    return
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_extension}") as temp_file:
                    temp_file.write(uploaded_file.read())
                    temp_file_path = temp_file.name
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return
            
            with st.spinner("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                result = st.session_state.manual_segmentator.load_audio(temp_file_path)
                
                if result.success:
                    st.session_state.manual_audio_loaded = True
                    st.success(result.message)
                else:
                    st.error(result.message)
                    return
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.unlink(temp_file_path)
        
        if st.session_state.manual_audio_loaded:
            display_manual_segmentation_interface()
    else:
        if st.session_state.manual_audio_loaded:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚ŒãŸå ´åˆã®ãƒªã‚»ãƒƒãƒˆ
            st.session_state.manual_audio_loaded = False
            st.session_state.manual_segmentator = None
            st.session_state.manual_segments = {}

def display_manual_segmentation_interface():
    """æ‰‹å‹•ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    segmentator = st.session_state.manual_segmentator
    
    # å†ç”Ÿç”¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
    if st.session_state.audio_player_state['audio_file_path'] is None:
        temp_audio_path = f"temp_audio_{int(time.time())}.wav"
        result = segmentator.save_audio_for_playback(temp_audio_path)
        success = result.success
        if success:
            st.session_state.audio_player_state['audio_file_path'] = temp_audio_path
    
    # Step 2: éŸ³å£°å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã¨æ³¢å½¢è¡¨ç¤º
    st.subheader("ğŸµ Step 2: éŸ³å£°å†ç”Ÿã¨æ³¢å½¢è¡¨ç¤º")
    
    # éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
    display_audio_controls(segmentator)
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ³¢å½¢è¡¨ç¤º
    display_interactive_waveform(segmentator)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆUI
    display_segment_creation_ui()
    
    # Step 3: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§ã¨ç®¡ç†
    segments = segmentator.get_segments_list()
    if segments:
        display_segment_management(segments)
        
        # Step 4: èªè­˜å®Ÿè¡Œ
        display_recognition_execution()
        
        # Step 5: çµæœè¡¨ç¤º
        display_manual_segmentation_results(segments)

# Phase 1: å†ç”Ÿä½ç½®ç®¡ç†ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def update_current_playback_position():
    """ç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚’è¨ˆç®—ãƒ»æ›´æ–°"""
    import time
    
    player_state = st.session_state.audio_player_state
    
    if not player_state['is_playing']:
        # å†ç”Ÿã—ã¦ã„ãªã„å ´åˆã¯ä¸€æ™‚åœæ­¢ä½ç½®ã‚’ç¶­æŒ
        return player_state['playback_paused_position']
    
    if player_state['playback_start_timestamp'] is None:
        # å†ç”Ÿé–‹å§‹æ™‚åˆ»ãŒæœªè¨­å®šã®å ´åˆã¯é–‹å§‹ä½ç½®
        return player_state['play_start_time']
    
    # å†ç”Ÿé–‹å§‹ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
    current_time = time.time()
    elapsed_time = current_time - player_state['playback_start_timestamp']
    
    # å†ç”Ÿé€Ÿåº¦ã‚’è€ƒæ…®
    adjusted_elapsed = elapsed_time * player_state['play_speed']
    
    # ç¾åœ¨ä½ç½®ã‚’è¨ˆç®—
    current_pos = player_state['playback_paused_position'] + adjusted_elapsed
    
    # å†ç”Ÿç¯„å›²å†…ã«åˆ¶é™
    play_end = player_state['play_end_time']
    if play_end and current_pos >= play_end:
        # å†ç”Ÿçµ‚äº†
        player_state['is_playing'] = False
        player_state['playback_paused_position'] = play_end
        return play_end
    
    # ç¾åœ¨ä½ç½®ã‚’æ›´æ–°
    player_state['current_position'] = current_pos
    player_state['last_update_time'] = current_time
    
    return current_pos

def set_playback_position(position):
    """å†ç”Ÿä½ç½®ã‚’æ‰‹å‹•è¨­å®š"""
    import time
    
    player_state = st.session_state.audio_player_state
    
    # ä½ç½®ã‚’ç¯„å›²å†…ã«åˆ¶é™
    play_start = player_state['play_start_time']
    play_end = player_state['play_end_time']
    
    if play_end:
        position = max(play_start, min(position, play_end))
    else:
        position = max(play_start, position)
    
    # ä½ç½®ã‚’è¨­å®š
    player_state['current_position'] = position
    player_state['playback_paused_position'] = position
    player_state['manual_position'] = position
    player_state['last_update_time'] = time.time()
    
    # å†ç”Ÿä¸­ã®å ´åˆã¯æ–°ã—ã„é–‹å§‹æ™‚åˆ»ã‚’è¨­å®š
    if player_state['is_playing']:
        player_state['playback_start_timestamp'] = time.time()

def set_segment_time_from_current_position(time_type: str):
    """ç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ™‚é–“ã«è¨­å®š
    
    Args:
        time_type: 'start' ã¾ãŸã¯ 'end'
    """
    # ãƒ‡ãƒãƒƒã‚°ç”¨: å†ç”ŸçŠ¶æ…‹ã‚’ç¢ºèª
    player_state = st.session_state.audio_player_state
    current_pos = update_current_playback_position()
    
    # ç¾åœ¨ã®å†ç”ŸçŠ¶æ…‹ã‚’ãƒ­ã‚°å‡ºåŠ›
    st.write(f"ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
    st.write(f"- å†ç”Ÿä¸­: {player_state['is_playing']}")
    st.write(f"- ç¾åœ¨ä½ç½®: {current_pos:.1f}ç§’")
    st.write(f"- ä¸€æ™‚åœæ­¢ä½ç½®: {player_state['playback_paused_position']:.1f}ç§’")
    st.write(f"- ç¾åœ¨ä½ç½®(current_position): {player_state['current_position']:.1f}ç§’")
    
    # ã‚ˆã‚Šç¢ºå®Ÿãªç¾åœ¨ä½ç½®å–å¾—
    if player_state['is_playing']:
        # å†ç”Ÿä¸­ã®å ´åˆ
        final_pos = current_pos
    else:
        # åœæ­¢ä¸­ã®å ´åˆã¯ current_position ã‚’ä½¿ç”¨
        final_pos = player_state.get('current_position', 0.0)
    
    if time_type == 'start':
        st.session_state.manual_segment_start_time = final_pos
        st.success(f"âœ… é–‹å§‹æ™‚é–“ã‚’ {final_pos:.1f}ç§’ ã«è¨­å®šã—ã¾ã—ãŸ")
    elif time_type == 'end':
        st.session_state.manual_segment_end_time = final_pos
        st.success(f"âœ… çµ‚äº†æ™‚é–“ã‚’ {final_pos:.1f}ç§’ ã«è¨­å®šã—ã¾ã—ãŸ")
    
    st.session_state.input_reset_counter += 1
    st.rerun()

def start_playback_from_position(position=None):
    """æŒ‡å®šä½ç½®ã‹ã‚‰å†ç”Ÿé–‹å§‹"""
    import time
    
    player_state = st.session_state.audio_player_state
    
    if position is not None:
        set_playback_position(position)
    
    # å†ç”ŸçŠ¶æ…‹ã‚’è¨­å®š
    player_state['is_playing'] = True
    player_state['playback_start_timestamp'] = time.time()
    player_state['last_update_time'] = time.time()

def display_audio_controls(segmentator):
    """éŸ³å£°å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«"""
    st.markdown("#### ğŸµ éŸ³å£°å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«")
    
    player_state = st.session_state.audio_player_state
    
    # å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³
    col1, col2, col3, col4, col5 = st.columns([1, 1, 1, 2, 1])
    
    with col1:
        if st.button("â–¶ï¸ å†ç”Ÿ", key="play_button"):
            handle_play_button(segmentator)
    
    with col2:
        if st.button("â¸ï¸ ä¸€æ™‚åœæ­¢", key="pause_button"):
            # Phase 1: ç¾åœ¨ä½ç½®ã‚’ä¿å­˜ã—ã¦ä¸€æ™‚åœæ­¢
            current_pos = update_current_playback_position()
            player_state['is_playing'] = False
            player_state['playback_paused_position'] = current_pos
            player_state['current_position'] = current_pos
    
    with col3:
        if st.button("â¹ï¸ åœæ­¢", key="stop_button"):
            # Phase 1: åœæ­¢ã—ã¦é–‹å§‹ä½ç½®ã«ãƒªã‚»ãƒƒãƒˆ
            player_state['is_playing'] = False
            player_state['playback_paused_position'] = player_state['play_start_time']
            player_state['current_position'] = player_state['play_start_time']
            player_state['manual_position'] = None
    
    with col4:
        # Phase 1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½ç½®è¡¨ç¤º
        current_pos = update_current_playback_position()
        total_time = segmentator.audio_duration
        play_end = player_state['play_end_time'] or total_time
        
        st.write(f"**ä½ç½®**: {current_pos:.1f}ç§’ / {play_end:.1f}ç§’")
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ï¼ˆå†ç”Ÿç¯„å›²ã«å¯¾ã™ã‚‹ç›¸å¯¾ä½ç½®ï¼‰
        play_start = player_state['play_start_time']
        play_duration = play_end - play_start
        relative_pos = (current_pos - play_start) / play_duration if play_duration > 0 else 0.0
        progress = max(0.0, min(relative_pos, 1.0))
        st.progress(progress)
    
    with col5:
        # å†ç”ŸçŠ¶æ…‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿
        status_icon = "ğŸ”´" if player_state['is_playing'] else "âšª"
        status_text = "å†ç”Ÿä¸­" if player_state['is_playing'] else "åœæ­¢ä¸­"
        st.write(f"{status_icon} {status_text}")
    
    # å†ç”Ÿè¨­å®š
    st.markdown("#### âš™ï¸ å†ç”Ÿè¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        selection_mode = st.selectbox(
            "å†ç”Ÿãƒ¢ãƒ¼ãƒ‰",
            options=["time_range", "segment", "full"],
            format_func=lambda x: {"time_range": "é¸æŠç¯„å›²", "segment": "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥", "full": "å…¨ä½“"}[x],
            index=["time_range", "segment", "full"].index(player_state['selection_mode'])
        )
        player_state['selection_mode'] = selection_mode
    
    with col2:
        auto_play = st.checkbox("è‡ªå‹•å†ç”Ÿ", value=player_state['auto_play'])
        player_state['auto_play'] = auto_play
    
    with col3:
        loop_play = st.checkbox("ãƒ«ãƒ¼ãƒ—å†ç”Ÿ", value=player_state['loop_play'])
        player_state['loop_play'] = loop_play
    
    # Phase 1: æ‰‹å‹•ä½ç½®è¨­å®šæ©Ÿèƒ½
    st.markdown("#### ğŸ¯ å†ç”Ÿä½ç½®è¨­å®š")
    col_pos1, col_pos2, col_pos3 = st.columns([2, 1, 1])
    
    with col_pos1:
        # ç¾åœ¨ä½ç½®è¡¨ç¤ºã¨æ‰‹å‹•è¨­å®š
        current_pos = update_current_playback_position()
        play_start = player_state['play_start_time']
        play_end = player_state['play_end_time'] or segmentator.audio_duration
        
        new_position = st.slider(
            "å†ç”Ÿä½ç½® (ç§’)",
            min_value=float(play_start),
            max_value=float(play_end),
            value=float(current_pos),
            step=0.1,
            format="%.1f",
            key="position_slider"
        )
        
        # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
        if abs(new_position - current_pos) > 0.05:  # 0.05ç§’ä»¥ä¸Šã®å·®ãŒã‚ã‚‹å ´åˆ
            set_playback_position(new_position)
    
    with col_pos2:
        if st.button("ğŸ“ ä½ç½®è¨­å®š", key="set_position"):
            position_input = st.number_input(
                "ä½ç½® (ç§’)",
                min_value=float(play_start),
                max_value=float(play_end),
                value=float(current_pos),
                step=0.1,
                key="manual_position_input"
            )
            set_playback_position(position_input)
    
    with col_pos3:
        if st.button("â–¶ï¸ ã“ã“ã‹ã‚‰å†ç”Ÿ", key="play_from_position"):
            start_playback_from_position()
    
    # éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼çµ±åˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    display_integrated_audio_player(segmentator, player_state)

def display_integrated_audio_player(segmentator, player_state):
    """çµ±åˆéŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ï¼šæ³¢å½¢è¡¨ç¤ºã¨é€£å‹•"""
    st.markdown("#### ğŸ”Š çµ±åˆéŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼")
    
    # ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚¿ãƒ–
    tab1, tab2, tab3 = st.tabs(["ğŸµ å…¨ä½“éŸ³å£°", "ğŸ“„ ç¯„å›²éŸ³å£°", "ğŸ¯ è¨­å®š"])
    
    with tab1:
        # å…¨ä½“éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼
        if player_state['audio_file_path'] and os.path.exists(player_state['audio_file_path']):
            st.markdown("**ğŸŒ å…¨ä½“éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«**")
            st.caption(f"éŸ³å£°é•·: {segmentator.audio_duration:.1f}ç§’")
            
            with open(player_state['audio_file_path'], 'rb') as audio_file:
                st.audio(audio_file.read(), format='audio/wav')
        else:
            st.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæº–å‚™ä¸­ã§ã™...")
    
    with tab2:
        # ç¯„å›²éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼
        display_range_audio_player(segmentator, player_state)
    
    with tab3:
        # ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼è¨­å®š
        display_player_settings(player_state)

def display_range_audio_player(segmentator, player_state):
    """ç¯„å›²éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼"""
    
    # å†ç”Ÿç¯„å›²ã¾ãŸã¯é¸æŠç¯„å›²ã®éŸ³å£°ã‚’ç”Ÿæˆ
    range_start = None
    range_end = None
    range_label = ""
    
    if player_state['play_end_time'] and player_state['play_start_time'] < player_state['play_end_time']:
        # å†ç”Ÿç¯„å›²ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        range_start = player_state['play_start_time']
        range_end = player_state['play_end_time']
        range_label = f"å†ç”Ÿç¯„å›² ({range_start:.1f}s - {range_end:.1f}s)"
        range_color = "ğŸ”µ"
    elif player_state['selection_start'] is not None and player_state['selection_end'] is not None:
        # é¸æŠç¯„å›²ãŒã‚ã‚‹å ´åˆ
        range_start = player_state['selection_start']
        range_end = player_state['selection_end']
        range_label = f"é¸æŠç¯„å›² ({range_start:.1f}s - {range_end:.1f}s)"
        range_color = "ğŸŸ¨"
    
    if range_start is not None and range_end is not None:
        range_duration = range_end - range_start
        st.markdown(f"**{range_color} {range_label}**")
        st.caption(f"ç¯„å›²é•·: {range_duration:.1f}ç§’")
        
        # ç¯„å›²éŸ³å£°ã®è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã¨ç”Ÿæˆ
        cache_key = f"{range_start:.1f}_{range_end:.1f}"
        has_cached_audio = (
            'range_audio_cache' in st.session_state and 
            cache_key in st.session_state.range_audio_cache and
            os.path.exists(st.session_state.range_audio_cache[cache_key]['path'])
        )
        
        # ç¯„å›²éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ/è¡¨ç¤º
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            if not has_cached_audio:
                if st.button("ğŸµ ç¯„å›²éŸ³å£°ã‚’ç”Ÿæˆ", key="generate_range_audio"):
                    generate_and_play_range_audio(segmentator, range_start, range_end, range_label)
            else:
                st.success("âœ… ç¯„å›²éŸ³å£°ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        
        with col2:
            if st.button("ğŸ”„ å†ç”Ÿæˆ", key="refresh_range_audio"):
                # è©²å½“ç¯„å›²ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã¿ã‚¯ãƒªã‚¢
                clear_specific_range_cache(cache_key)
                generate_and_play_range_audio(segmentator, range_start, range_end, range_label)
        
        with col3:
            if has_cached_audio and st.button("ğŸ—‘ï¸ å‰Šé™¤", key="delete_range_audio"):
                clear_specific_range_cache(cache_key)
                st.success("å‰Šé™¤å®Œäº†")
                st.rerun()
        
        # æ—¢å­˜ã®ç¯„å›²éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°è¡¨ç¤º
        if has_cached_audio:
            display_cached_range_audio(range_start, range_end)
        
        # è‡ªå‹•ç”Ÿæˆã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if not has_cached_audio:
            if st.checkbox("ğŸš€ è‡ªå‹•ç”Ÿæˆï¼ˆç¯„å›²å¤‰æ›´æ™‚ã«è‡ªå‹•ã§éŸ³å£°ç”Ÿæˆï¼‰", key="auto_generate_range"):
                generate_and_play_range_audio(segmentator, range_start, range_end, range_label)
        
    else:
        st.info("ğŸ“ **ç¯„å›²æœªé¸æŠ**\n\nå†ç”Ÿç¯„å›²ã¾ãŸã¯é¸æŠç¯„å›²ã‚’è¨­å®šã™ã‚‹ã¨ã€ãã®éƒ¨åˆ†ã®éŸ³å£°ã‚’å†ç”Ÿã§ãã¾ã™ã€‚")

def generate_and_play_range_audio(segmentator, start_time, end_time, label):
    """ç¯„å›²éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º"""
    import tempfile
    import time
    
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        timestamp = int(time.time())
        temp_filename = f"range_audio_{start_time:.1f}_{end_time:.1f}_{timestamp}.wav"
        temp_path = os.path.join(tempfile.gettempdir(), temp_filename)
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—
        time_axis, audio_data, sample_rate = segmentator.get_waveform_data()
        
        # ç¯„å›²ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        start_sample = int(start_time * sample_rate)
        end_sample = int(end_time * sample_rate)
        range_audio = audio_data[start_sample:end_sample]
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        import soundfile as sf
        sf.write(temp_path, range_audio, sample_rate)
        
        # session_stateã«ä¿å­˜
        if 'range_audio_cache' not in st.session_state:
            st.session_state.range_audio_cache = {}
        
        cache_key = f"{start_time:.1f}_{end_time:.1f}"
        st.session_state.range_audio_cache[cache_key] = {
            'path': temp_path,
            'label': label,
            'duration': end_time - start_time,
            'timestamp': timestamp
        }
        
        st.success(f"âœ… {label} ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
        st.rerun()
        
    except Exception as e:
        st.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def display_cached_range_audio(start_time, end_time):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸç¯„å›²éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º"""
    if 'range_audio_cache' not in st.session_state:
        return
    
    cache_key = f"{start_time:.1f}_{end_time:.1f}"
    if cache_key in st.session_state.range_audio_cache:
        cache_data = st.session_state.range_audio_cache[cache_key]
        
        if os.path.exists(cache_data['path']):
            st.markdown(f"**ğŸµ {cache_data['label']}**")
            st.caption(f"é•·ã•: {cache_data['duration']:.1f}ç§’")
            
            with open(cache_data['path'], 'rb') as audio_file:
                st.audio(audio_file.read(), format='audio/wav')
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚‚å‰Šé™¤
            del st.session_state.range_audio_cache[cache_key]

def clear_range_audio_cache():
    """ç¯„å›²éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
    if 'range_audio_cache' in st.session_state:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for cache_data in st.session_state.range_audio_cache.values():
            if os.path.exists(cache_data['path']):
                try:
                    os.unlink(cache_data['path'])
                except:
                    pass  # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
        st.session_state.range_audio_cache.clear()

def clear_specific_range_cache(cache_key):
    """ç‰¹å®šç¯„å›²ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã¿ã‚¯ãƒªã‚¢"""
    if 'range_audio_cache' in st.session_state and cache_key in st.session_state.range_audio_cache:
        cache_data = st.session_state.range_audio_cache[cache_key]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(cache_data['path']):
            try:
                os.unlink(cache_data['path'])
            except:
                pass  # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤
        del st.session_state.range_audio_cache[cache_key]

def display_player_settings(player_state):
    """ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼è¨­å®š"""
    st.markdown("**âš™ï¸ è¡¨ç¤ºè¨­å®š**")
    
    # è¡¨ç¤ºãƒ•ãƒ©ã‚°ã®è¨­å®š
    col1, col2 = st.columns(2)
    
    with col1:
        show_playback_pos = st.checkbox(
            "å†ç”Ÿä½ç½®ç·šã‚’è¡¨ç¤º",
            value=player_state['show_playback_position'],
            key="toggle_playback_position"
        )
        player_state['show_playback_position'] = show_playback_pos
    
    with col2:
        show_playback_range = st.checkbox(
            "å†ç”Ÿç¯„å›²ã‚’è¡¨ç¤º",
            value=player_state['show_playback_range'],
            key="toggle_playback_range"
        )
        player_state['show_playback_range'] = show_playback_range
    
    st.markdown("**ğŸ”§ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†**")
    if st.button("ğŸ—‘ï¸ ç¯„å›²éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢", key="clear_cache_button"):
        clear_range_audio_cache()
        st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³è¡¨ç¤º
    if 'range_audio_cache' in st.session_state and st.session_state.range_audio_cache:
        st.markdown("**ğŸ“‚ ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³**")
        for key, data in st.session_state.range_audio_cache.items():
            file_exists = "âœ…" if os.path.exists(data['path']) else "âŒ"
            st.caption(f"{file_exists} {data['label']} ({data['duration']:.1f}ç§’)")

def handle_play_button(segmentator):
    """å†ç”Ÿãƒœã‚¿ãƒ³ã®å‡¦ç†ï¼ˆPhase 1å¯¾å¿œï¼‰"""
    player_state = st.session_state.audio_player_state
    
    if player_state['selection_mode'] == 'time_range':
        # é¸æŠç¯„å›²å†ç”Ÿ
        if player_state['selection_start'] is not None and player_state['selection_end'] is not None:
            player_state['play_start_time'] = player_state['selection_start']
            player_state['play_end_time'] = player_state['selection_end']
        else:
            st.warning("å†ç”Ÿç¯„å›²ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ³¢å½¢ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return
    elif player_state['selection_mode'] == 'full':
        # å…¨ä½“å†ç”Ÿ
        player_state['play_start_time'] = 0.0
        player_state['play_end_time'] = segmentator.audio_duration
    else:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†ç”Ÿï¼ˆä»Šã¯å…¨ä½“å†ç”Ÿã¨ã—ã¦æ‰±ã†ï¼‰
        player_state['play_start_time'] = 0.0
        player_state['play_end_time'] = segmentator.audio_duration
    
    # Phase 1: æ–°ã—ã„ä½ç½®ç®¡ç†æ©Ÿèƒ½ã‚’ä½¿ç”¨
    start_position = player_state.get('manual_position', player_state['play_start_time'])
    start_playback_from_position(start_position)
    
    st.success(f"å†ç”Ÿé–‹å§‹: {player_state['play_start_time']:.1f}s - {player_state['play_end_time']:.1f}s")

def display_interactive_waveform(segmentator):
    """audixå¯¾å¿œ: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸæ³¢å½¢è¡¨ç¤º"""
    st.markdown("#### ğŸµ é«˜åº¦éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ (Audix)")
    st.caption("ğŸ’¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿä½ç½®è¿½è·¡ | ç¯„å›²é¸æŠå¯¾å¿œ | å®Œå…¨åŒæœŸ")
    
    # audixã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from streamlit_advanced_audio import audix, WaveSurferOptions, CustomizedRegion
    except ImportError:
        st.error("ğŸš¨ streamlit-advanced-audio ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.code("pip install streamlit-advanced-audio")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—¢å­˜ã®Plotlyè¡¨ç¤º
        display_fallback_waveform(segmentator)
        return
    
    # æ³¢å½¢ãƒ‡ãƒ¼ã‚¿å–å¾—
    time_axis, audio_data, sample_rate = segmentator.get_waveform_data()
    player_state = st.session_state.audio_player_state
    
    # audixç”¨ã®è¨­å®š
    wavesurfer_options = WaveSurferOptions(
        wave_color="#1f77b4",          # æ³¢å½¢ã®è‰²
        progress_color="#ff4444",       # å†ç”Ÿä½ç½®ã®è‰²
        height=200,                     # æ³¢å½¢ã®é«˜ã•
        bar_width=1,                   # ãƒãƒ¼ã®å¹…
        bar_gap=0,                     # ãƒãƒ¼ã®é–“éš”
        normalize=True                 # æ­£è¦åŒ–
    )
    
    # æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¯„å›²ã¨ã—ã¦è¡¨ç¤º
    regions = []
    segments = segmentator.get_segments_list()
    segment_colors = ['rgba(255, 127, 14, 0.3)', 'rgba(44, 160, 44, 0.3)', 
                     'rgba(214, 39, 40, 0.3)', 'rgba(148, 103, 189, 0.3)']
    
    for i, segment in enumerate(segments):
        color = segment_colors[i % len(segment_colors)]
        
        regions.append(CustomizedRegion(
            start=segment.start_time,
            end=segment.end_time,
            color=color
        ))
    
    # å†ç”Ÿç¯„å›²ãŒã‚ã‚‹å ´åˆã¯ç¯„å›²ã¨ã—ã¦è¿½åŠ 
    if (player_state['play_end_time'] and 
        player_state['play_start_time'] < player_state['play_end_time']):
        regions.append(CustomizedRegion(
            start=player_state['play_start_time'],
            end=player_state['play_end_time'],
            color="rgba(173, 216, 230, 0.5)"
        ))
    
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼šaudixãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ + ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«  
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # audixãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚’è¡¨ç¤º
        result = audix(
            audio_data,
            sample_rate=sample_rate,
            wavesurfer_options=wavesurfer_options,
            customized_regions=regions if regions else [],
            key="main_audio_player"
        )
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸå‡¦ç†
        sync_audio_player_state(result, player_state)
        
        # é¸æŠç¯„å›²ã®å‡¦ç†
        handle_region_selection(result, player_state)
    
    with col2:
        # å³å´ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
        display_audio_control_panel(segmentator, player_state)

def display_audio_control_panel(segmentator, player_state):
    """å³å´éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«"""
    st.markdown("### ğŸ“‹ ç¯„å›²é¸æŠã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ")
    
    # æ•°å€¤å…¥åŠ›ã«ã‚ˆã‚‹ç¯„å›²é¸æŠï¼ˆç¾åœ¨ä½ç½®ãƒœã‚¿ãƒ³ä»˜ãï¼‰
    col_a, col_b = st.columns(2)
    with col_a:
        # é–‹å§‹æ™‚é–“è¨­å®šã‚¨ãƒªã‚¢
        st.markdown("**é–‹å§‹æ™‚é–“**")
        subcol1, subcol2 = st.columns([1, 3])
        with subcol1:
            if st.button("ğŸ“", key="set_start_from_current", 
                        help="ç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚’é–‹å§‹æ™‚é–“ã«è¨­å®š"):
                set_segment_time_from_current_position('start')
        with subcol2:
            quick_start = st.number_input(
                "é–‹å§‹(ç§’)", 
                min_value=0.0, 
                max_value=float(segmentator.audio_duration),
                value=float(st.session_state.manual_segment_start_time), 
                step=0.5,
                key=f"quick_start_{st.session_state.input_reset_counter}",
                label_visibility="collapsed"
            )
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
            st.session_state.manual_segment_start_time = quick_start
            
    with col_b:
        # çµ‚äº†æ™‚é–“è¨­å®šã‚¨ãƒªã‚¢
        st.markdown("**çµ‚äº†æ™‚é–“**")
        subcol1, subcol2 = st.columns([1, 3])
        with subcol1:
            if st.button("ğŸ“", key="set_end_from_current",
                        help="ç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚’çµ‚äº†æ™‚é–“ã«è¨­å®š"):
                set_segment_time_from_current_position('end')
        with subcol2:
            quick_end = st.number_input(
                "çµ‚äº†(ç§’)", 
                min_value=0.0, 
                max_value=float(segmentator.audio_duration),
                value=float(st.session_state.manual_segment_end_time), 
                step=0.5,
                key=f"quick_end_{st.session_state.input_reset_counter}",
                label_visibility="collapsed"
            )
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
            st.session_state.manual_segment_end_time = quick_end
    
    # Phase 3: å†ç”Ÿç¯„å›²ã‚³ãƒ”ãƒ¼æ©Ÿèƒ½ï¼ˆaudixé¸æŠç¯„å›²ã‚‚è€ƒæ…®ï¼‰
    st.markdown("**ğŸ”„ ç¯„å›²é€£æº**")
    if player_state['play_end_time']:
        play_duration = player_state['play_end_time'] - player_state['play_start_time']
        st.info(f"ç¾åœ¨ã®å†ç”Ÿç¯„å›²: {player_state['play_start_time']:.1f}s - {player_state['play_end_time']:.1f}s ({play_duration:.1f}ç§’)")
        
        if st.button("ğŸ“‹ å†ç”Ÿç¯„å›²â†’é¸æŠç¯„å›²", key="copy_playback_to_selection"):
            player_state['selection_start'] = player_state['play_start_time']
            player_state['selection_end'] = player_state['play_end_time']
            st.success(f"å†ç”Ÿç¯„å›²ã‚’é¸æŠç¯„å›²ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ: {player_state['play_start_time']:.1f}s - {player_state['play_end_time']:.1f}s")
            st.session_state.input_reset_counter += 1
            st.rerun()
    
    # ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã«é…ç½®
    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("ğŸ“ ã“ã®ç¯„å›²ã‚’é¸æŠ", key="quick_select"):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰æœ€æ–°ã®å€¤ã‚’ä½¿ç”¨
            start_time = st.session_state.manual_segment_start_time
            end_time = st.session_state.manual_segment_end_time
            if end_time > start_time:
                player_state['selection_start'] = start_time
                player_state['selection_end'] = end_time
                st.success(f"ç¯„å›²é¸æŠ: {start_time:.1f}s - {end_time:.1f}s")
                st.rerun()
            else:
                st.error("çµ‚äº†æ™‚é–“ã¯é–‹å§‹æ™‚é–“ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
    
    with col_btn2:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ãƒœã‚¿ãƒ³
        if player_state['selection_start'] is not None and player_state['selection_end'] is not None:
            if st.button("â• ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ", type="primary", key="add_segment_right_panel"):
                result = st.session_state.manual_segmentator.create_segment(
                    player_state['selection_start'], player_state['selection_end']
                )
                if result.success:
                    st.success(result.message)
                    # é¸æŠã‚’ãƒªã‚»ãƒƒãƒˆ
                    player_state['selection_start'] = None
                    player_state['selection_end'] = None
                    st.session_state.input_reset_counter += 1
                    st.rerun()
                else:
                    st.error(result.message)
        else:
            st.button("â• ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ", disabled=True, help="å…ˆã«ç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    # é¸æŠçŠ¶æ…‹ã®è¡¨ç¤º
    if player_state['selection_start'] is not None and player_state['selection_end'] is not None:
        duration = player_state['selection_end'] - player_state['selection_start']
        st.success(f"âœ… **é¸æŠæ¸ˆã¿**\n\nğŸ• {player_state['selection_start']:.1f}s - {player_state['selection_end']:.1f}s\n\nâ±ï¸ é•·ã•: {duration:.1f}ç§’")
        
        # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.button("ğŸ—‘ï¸ é¸æŠã‚’ã‚¯ãƒªã‚¢", key="clear_selection_right"):
            player_state['selection_start'] = None
            player_state['selection_end'] = None
            st.session_state.input_reset_counter += 1
            st.success("é¸æŠã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            st.rerun()
    else:
        st.info("ğŸ“ **ä¸Šè¨˜ã§ç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„**")

def sync_audio_player_state(result, player_state):
    """audixã¨session_stateã®å®Œå…¨åŒæœŸ"""
    if result:
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½ç½®åŒæœŸ
        current_time = result.get("currentTime", 0.0)
        is_playing = result.get("isPlaying", False)
        
        # session_stateã‚’æ›´æ–°
        player_state['current_position'] = current_time
        player_state['is_playing'] = is_playing
        
        # å†ç”ŸçŠ¶æ…‹ã®è¡¨ç¤º
        col1, col2, col3 = st.columns(3)
        
        with col1:
            status_icon = "ğŸ”´" if is_playing else "âšª"
            status_text = "å†ç”Ÿä¸­" if is_playing else "åœæ­¢ä¸­"
            st.write(f"{status_icon} **{status_text}**")
        
        with col2:
            st.write(f"ğŸ“ **ä½ç½®**: {current_time:.2f}ç§’")
        
        with col3:
            # ç·æ™‚é–“ã‹ã‚‰ã®é€²æ—
            total_time = player_state.get('play_end_time') or 30.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            progress = min(current_time / total_time, 1.0) if total_time > 0 else 0.0
            st.progress(progress)

def handle_region_selection(result, player_state):
    """ç¯„å›²é¸æŠã®å‡¦ç†"""
    if result and result.get("selectedRegion"):
        region = result["selectedRegion"]
        start_time = region.get("start", 0.0)
        end_time = region.get("end", 0.0)
        
        if start_time < end_time:
            # é¸æŠç¯„å›²ã‚’session_stateã«åæ˜ 
            player_state['selection_start'] = start_time
            player_state['selection_end'] = end_time
            
            # é¸æŠæƒ…å ±ã‚’è¡¨ç¤º
            duration = end_time - start_time
            st.success(f"âœ… **ç¯„å›²é¸æŠå®Œäº†**: {start_time:.2f}s - {end_time:.2f}s (é•·ã•: {duration:.2f}ç§’)")

def display_fallback_waveform(segmentator):
    """audixãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤º"""
    st.warning("âš ï¸ é«˜åº¦éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬è¡¨ç¤ºã‚’ä½¿ç”¨ä¸­...")
    
    # æ—¢å­˜ã®Plotlyè¡¨ç¤ºï¼ˆç°¡ç´ ç‰ˆï¼‰
    time_axis, audio_data, sample_rate = segmentator.get_waveform_data()
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=time_axis,
        y=audio_data,
        mode='lines',
        name='éŸ³å£°æ³¢å½¢',
        line=dict(color='#1f77b4', width=1.5),
        showlegend=False
    ))
    
    # æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º
    segments = segmentator.get_segments_list()
    segment_colors = ['#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22']
    
    for i, segment in enumerate(segments):
        color = segment_colors[i % len(segment_colors)]
        speaker_name = segment.assigned_speaker or segment.top_speaker or f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{segment.id}"
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé ˜åŸŸã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        fig.add_vrect(
            x0=segment.start_time,
            x1=segment.end_time,
            fillcolor=color,
            opacity=0.25,
            annotation_text=f"#{segment.id}: {speaker_name}",
            annotation_position="top left",
            annotation=dict(
                font=dict(size=10, color='white'),
                bgcolor=color,
                bordercolor='white',
                borderwidth=1
            )
        )
    
    # é¸æŠç¯„å›²ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºï¼ˆæœ€å‰é¢ï¼‰
    if player_state['selection_start'] is not None and player_state['selection_end'] is not None:
        selection_start = min(player_state['selection_start'], player_state['selection_end'])
        selection_end = max(player_state['selection_start'], player_state['selection_end'])
        duration = selection_end - selection_start
        
        fig.add_vrect(
            x0=selection_start,
            x1=selection_end,
            fillcolor='rgba(255, 255, 0, 0.3)',  # é»„è‰²ã§åŠé€æ˜
            line=dict(color='gold', width=3),
            annotation_text=f"é¸æŠç¯„å›²: {duration:.1f}ç§’",
            annotation_position="top left",
            annotation=dict(
                font=dict(size=12, color='black'),
                bgcolor='gold',
                bordercolor='orange',
                borderwidth=2
            )
        )
        
        # é¸æŠç¯„å›²ã®å¢ƒç•Œç·š
        fig.add_vline(
            x=selection_start,
            line=dict(color='orange', width=3, dash='solid'),
            annotation_text=f"é–‹å§‹: {selection_start:.1f}s"
        )
        fig.add_vline(
            x=selection_end,
            line=dict(color='red', width=3, dash='solid'),
            annotation_text=f"çµ‚äº†: {selection_end:.1f}s"
        )
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
    fig.update_layout(
        title="ğŸµ éŸ³å£°æ³¢å½¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤ºï¼‰",
        xaxis_title="æ™‚é–“ (ç§’)",
        yaxis_title="æŒ¯å¹…",
        height=400,
        showlegend=False
    )
    
    st.plotly_chart(fig, use_container_width=True)




def display_segment_creation_ui():
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆã®æ“ä½œã‚¬ã‚¤ãƒ‰"""
    st.subheader("âœ‚ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆã‚¬ã‚¤ãƒ‰")
    
    # é¸æŠçŠ¶æ…‹ã®ç¢ºèªè¡¨ç¤º
    player_state = st.session_state.audio_player_state
    if player_state['selection_start'] is not None and player_state['selection_end'] is not None:
        start_time = player_state['selection_start']
        end_time = player_state['selection_end']
        duration = end_time - start_time
        st.success(f"âœ… **ç¾åœ¨ã®é¸æŠ**: {start_time:.1f}s - {end_time:.1f}s (é•·ã•: {duration:.1f}ç§’)")
        st.info("ğŸ‘† ä¸Šè¨˜ã®æ³¢å½¢ã‚¨ãƒªã‚¢å³å´ã®ã€Œâ• ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ã€ãƒœã‚¿ãƒ³ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã§ãã¾ã™")
    else:
        st.info("ğŸ“ **ç¯„å›²ãŒæœªé¸æŠ**: ä¸Šè¨˜ã®æ³¢å½¢ã‚¨ãƒªã‚¢å³å´ã§ç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    st.markdown("""
    ### ğŸ“‹ ä½¿ç”¨æ–¹æ³•
    
    1. **ç¯„å›²é¸æŠ**: æ³¢å½¢è¡¨ç¤ºå³å´ã®ã€Œç¯„å›²é¸æŠã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ã€ã§é–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ã‚’å…¥åŠ›
    2. **é¸æŠå®Ÿè¡Œ**: ã€ŒğŸ“ ã“ã®ç¯„å›²ã‚’é¸æŠã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. **ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ **: ã€Œâ• ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. **å®Œäº†**: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæ³¢å½¢ä¸Šã«è‰²ä»˜ãã§è¡¨ç¤ºã•ã‚Œã¾ã™
    
    ### âš ï¸ æ³¨æ„ç‚¹
    
    - **æœ€å°é•·ã•**: 0.5ç§’ä»¥ä¸Š
    - **é‡è¤‡ç¦æ­¢**: æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã®é‡è¤‡ã¯ä¸å¯
    - **ç¯„å›²åˆ¶é™**: éŸ³å£°ç¯„å›²å†…ã®æ™‚é–“ã®ã¿æŒ‡å®šå¯èƒ½
    
    ### ğŸ’¡ ãƒ’ãƒ³ãƒˆ
    
    - æ³¢å½¢ã‚’è¦‹ãªãŒã‚‰éŸ³å£°ã®åŒºåˆ‡ã‚Šã‚’ç¢ºèªã—ã¦ç¯„å›²ã‚’æ±ºã‚ã¦ãã ã•ã„
    - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ å¾Œã¯è‡ªå‹•çš„ã«é¸æŠãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã™
    - é–“é•ãˆãŸå ´åˆã¯ã€ŒğŸ—‘ï¸ é¸æŠã‚’ã‚¯ãƒªã‚¢ã€ã§é¸æŠã‚’å–ã‚Šæ¶ˆã›ã¾ã™
    """)

def display_segment_management(segments):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç®¡ç†è¡¨ç¤º"""
    st.subheader("ğŸ“‹ Step 3: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§")
    
    if not segments:
        st.info("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šè¨˜ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«
    segment_data = []
    for segment in segments:
        status = "èªè­˜æ¸ˆã¿" if segment.is_recognized else "æœªèªè­˜"
        confidence = segment.confidence_level or "-"
        top_speaker = segment.top_speaker or "-"
        top_score = f"{segment.top_score:.3f}" if segment.top_score else "-"
        
        segment_data.append({
            "ID": segment.id,
            "é–‹å§‹": f"{segment.start_time:.1f}s",
            "çµ‚äº†": f"{segment.end_time:.1f}s",
            "é•·ã•": f"{segment.duration:.1f}s",
            "çŠ¶æ…‹": status,
            "æœ€ä¸Šä½å€™è£œ": top_speaker,
            "ã‚¹ã‚³ã‚¢": top_score,
            "ä¿¡é ¼åº¦": confidence
        })
    
    df = pd.DataFrame(segment_data)
    st.dataframe(df, use_container_width=True)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ“ä½œ
    st.subheader("ğŸ”§ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ“ä½œ")
    col1, col2 = st.columns(2)
    
    with col1:
        delete_id = st.selectbox(
            "å‰Šé™¤ã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ",
            options=[0] + [s.id for s in segments],
            format_func=lambda x: "é¸æŠã—ã¦ãã ã•ã„" if x == 0 else f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {x}"
        )
        
        if st.button("ğŸ—‘ï¸ å‰Šé™¤") and delete_id > 0:
            result = st.session_state.manual_segmentator.delete_segment(delete_id)
            if result.success:
                st.success(result.message)
                st.rerun()
            else:
                st.error(result.message)
    
    with col2:
        st.write("**å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¯ãƒªã‚¢**")
        if st.button("ğŸ—‘ï¸ å…¨å‰Šé™¤", help="ã™ã¹ã¦ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã™"):
            st.session_state.manual_segmentator.segment_manager.clear_segments()
            st.success("å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            st.rerun()

def display_recognition_execution():
    """èªè­˜å®Ÿè¡ŒUI"""
    st.subheader("ğŸ¯ Step 4: èªè­˜å®Ÿè¡Œ")
    
    segments = st.session_state.manual_segmentator.get_segments_list()
    unrecognized_count = sum(1 for s in segments if not s.is_recognized)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.write(f"**èªè­˜å¯¾è±¡**: {len(segments)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ (æœªèªè­˜: {unrecognized_count})")
        
        if st.button("ğŸš€ å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆèªè­˜å®Ÿè¡Œ", type="primary", disabled=len(segments)==0):
            with st.spinner("èªè­˜å‡¦ç†ä¸­..."):
                progress_bar = st.progress(0)
                
                # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å€‹åˆ¥ã«å‡¦ç†ã—ã¦ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
                total_segments = len(segments)
                success_count = 0
                
                # ãƒãƒƒãƒèªè­˜å®Ÿè¡Œ
                result = st.session_state.manual_segmentator.recognize_all_segments(
                    show_jvs=st.session_state.manual_show_jvs,
                    show_cv=st.session_state.manual_show_cv
                )
                
                progress_bar.progress(100)
                
                if result.success:
                    st.success(result.message)
                    st.rerun()
                else:
                    st.error(result.message)
    
    with col2:
        if unrecognized_count > 0:
            st.info(f"ğŸ’¡ {unrecognized_count}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒ\næœªèªè­˜ã§ã™")
        else:
            st.success("âœ… ã™ã¹ã¦èªè­˜æ¸ˆã¿")

def display_manual_segmentation_results(segments):
    """æ‰‹å‹•åˆ†é›¢çµæœè¡¨ç¤º"""
    if not any(s.is_recognized for s in segments):
        return
    
    # èªè­˜çµæœè©³ç´°è¡¨ç¤º
    st.subheader("ğŸ† Step 5: èªè­˜çµæœè©³ç´°")
    
    for segment in segments:
        if not segment.is_recognized:
            continue
        
        with st.expander(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment.id} ({segment.start_time:.1f}s - {segment.end_time:.1f}s)"):
            st.write(f"**é•·ã•**: {segment.duration:.1f}ç§’")
            st.write(f"**ä¿¡é ¼åº¦**: {segment.confidence_level}")
            
            if segment.recognition_results:
                st.write("**Top-5 èªè­˜å€™è£œ:**")
                for result in segment.recognition_results[:5]:
                    rank_icon = "ğŸ¥‡" if result['rank'] == 1 else "ğŸ¥ˆ" if result['rank'] == 2 else "ğŸ¥‰" if result['rank'] == 3 else f"{result['rank']}."
                    st.write(f"{rank_icon} {result['speaker']}: `{result['score']:.3f}`")
    
    # è©±è€…å‰²ã‚Šå½“ã¦ã¨æœ€çµ‚çµæœ
    display_speaker_assignment_and_timeline(segments)

def display_speaker_assignment_and_timeline(segments):
    """è©±è€…å‰²ã‚Šå½“ã¦ã¨æœ€çµ‚ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¡¨ç¤º"""
    recognized_segments = [s for s in segments if s.is_recognized]
    if not recognized_segments:
        return
    
    st.subheader("ğŸ·ï¸ Step 6: è©±è€…å‰²ã‚Šå½“ã¦")
    
    # ç™»éŒ²è©±è€…ä¸€è¦§å–å¾—
    available_speakers = []
    if st.session_state.recognizer and st.session_state.recognizer.speaker_embeddings:
        all_speakers = list(st.session_state.recognizer.speaker_embeddings.keys())
        
        # ã‚«ã‚¹ã‚¿ãƒ è©±è€…
        custom_speakers = [s for s in all_speakers if not (s.startswith('jvs') or s.startswith('cv_') or s.startswith('commonvoice_'))]
        available_speakers.extend(custom_speakers)
        
        # JVSè©±è€…ï¼ˆè¨­å®šã«ã‚ˆã‚Šè¡¨ç¤ºï¼‰
        if st.session_state.manual_show_jvs:
            jvs_speakers = [s for s in all_speakers if s.startswith('jvs')]
            available_speakers.extend([f"{s} ğŸ—¾" for s in jvs_speakers])
        
        # Common Voiceè©±è€…ï¼ˆè¨­å®šã«ã‚ˆã‚Šè¡¨ç¤ºï¼‰
        if st.session_state.manual_show_cv:
            cv_speakers = [s for s in all_speakers if s.startswith(('cv_', 'commonvoice_'))]
            available_speakers.extend([f"{s} ğŸŒ" for s in cv_speakers])
    
    available_speakers.extend(["unknown", "æ–°è¦è©±è€…..."])
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¯ã®è©±è€…å‰²ã‚Šå½“ã¦
    assignment_changed = False
    
    for segment in recognized_segments:
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            st.write(f"**ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment.id}**")
            st.write(f"({segment.start_time:.1f}s - {segment.end_time:.1f}s)")
        
        with col2:
            current_assignment = segment.assigned_speaker or segment.top_speaker or "unknown"
            
            # ç¾åœ¨ã®å‰²ã‚Šå½“ã¦ãŒãƒªã‚¹ãƒˆã«ãªã„å ´åˆã¯è¿½åŠ 
            if current_assignment not in available_speakers and current_assignment:
                available_speakers.insert(-2, current_assignment)
            
            # è©±è€…é¸æŠ
            selected_speaker = st.selectbox(
                "è©±è€…å‰²ã‚Šå½“ã¦",
                options=available_speakers,
                index=available_speakers.index(current_assignment) if current_assignment in available_speakers else 0,
                key=f"speaker_assignment_{segment.id}"
            )
            
            # æ–°è¦è©±è€…ã®å ´åˆ
            if selected_speaker == "æ–°è¦è©±è€…...":
                new_speaker = st.text_input(f"æ–°è¦è©±è€…å (ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{segment.id})", key=f"new_speaker_{segment.id}")
                if new_speaker:
                    selected_speaker = new_speaker
            
            # å‰²ã‚Šå½“ã¦æ›´æ–°
            if selected_speaker != segment.assigned_speaker and selected_speaker != "æ–°è¦è©±è€…...":
                segment.assigned_speaker = selected_speaker
                assignment_changed = True
        
        with col3:
            # äºˆæ¸¬çµæœè¡¨ç¤º
            if segment.top_speaker:
                st.write("**äºˆæ¸¬çµæœ**")
                st.write(f"{segment.top_speaker}")
                st.write(f"`{segment.top_score:.3f}`")
    
    # æœ€çµ‚ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¡¨ç¤º
    if assignment_changed or st.button("ğŸ¨ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç”Ÿæˆ"):
        display_final_timeline()

def display_final_timeline():
    """æœ€çµ‚ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¡¨ç¤ºï¼ˆGanttã‚¹ã‚¿ã‚¤ãƒ«ï¼‰"""
    import plotly.colors as pc
    
    st.subheader("ğŸ“Š æœ€çµ‚çµæœ: è©±è€…åˆ¥ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
    
    timeline_data = st.session_state.manual_segmentator.get_timeline_data()
    
    if not timeline_data['speakers']:
        st.info("è©±è€…ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # è©±è€…ä¸€è¦§ã¨ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
    speakers = list(timeline_data['speakers'].keys())
    speakers.sort()  # ä¸€è²«ã—ãŸé †åº
    colors = pc.qualitative.Set2[:len(speakers)]
    speaker_colors = dict(zip(speakers, colors))
    
    # Plotly Ganttã‚¹ã‚¿ã‚¤ãƒ«ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ä½œæˆ
    fig = go.Figure()
    
    # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’Ganttãƒãƒ£ãƒ¼ãƒˆã¨ã—ã¦è¿½åŠ 
    for speaker, data in timeline_data['speakers'].items():
        for segment in data['segments']:
            # ä¿¡é ¼åº¦ã®è¡¨ç¤ºç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™
            confidence_text = f"{segment['confidence']:.3f}" if segment['confidence'] is not None else "N/A"
            
            # ãƒ›ãƒãƒ¼æƒ…å ±
            hover_text = (
                f"è©±è€…: {speaker}<br>"
                f"æ™‚é–“: {segment['start']:.1f}s - {segment['end']:.1f}s<br>"
                f"æ™‚é–“é•·: {segment['duration']:.1f}s<br>"
                f"ä¿¡é ¼åº¦: {confidence_text}"
            )
            
            fig.add_trace(go.Bar(
                x=[segment['duration']],
                y=[speaker],
                base=segment['start'],
                orientation='h',
                name=speaker,
                marker_color=speaker_colors[speaker],
                hovertemplate=hover_text + "<extra></extra>",
                showlegend=False
            ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
    fig.update_layout(
        title="ğŸ‘¥ è©±è€…åˆ¥ç™ºè©±ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
        xaxis_title="æ™‚é–“ï¼ˆç§’ï¼‰",
        yaxis_title="è©±è€…",
        height=max(300, len(speakers) * 60),
        showlegend=False,
        barmode='overlay'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # çµ±è¨ˆæƒ…å ±
    display_manual_statistics(timeline_data)
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    display_export_options()

def display_manual_statistics(timeline_data):
    """çµ±è¨ˆæƒ…å ±è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ çµ±è¨ˆæƒ…å ±")
    
    stats_data = []
    total_speech_time = 0
    
    for speaker, data in timeline_data['speakers'].items():
        total_time = data['total_time']
        segment_count = data['segment_count']
        avg_confidence = np.mean([s['confidence'] for s in data['segments'] if s['confidence'] is not None])
        speech_ratio = (total_time / timeline_data['total_duration']) * 100
        
        stats_data.append({
            "è©±è€…å": speaker,
            "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°": segment_count,
            "ç·ç™ºè©±æ™‚é–“": f"{total_time:.1f}ç§’",
            "å¹³å‡ä¿¡é ¼åº¦": f"{avg_confidence:.3f}" if not np.isnan(avg_confidence) else "-",
            "ç™ºè©±å‰²åˆ": f"{speech_ratio:.1f}%"
        })
        
        total_speech_time += total_time
    
    # çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«
    stats_df = pd.DataFrame(stats_data)
    st.dataframe(stats_df, use_container_width=True)
    
    # ã‚µãƒãƒªãƒ¼æƒ…å ±
    silence_time = timeline_data['total_duration'] - total_speech_time
    silence_ratio = (silence_time / timeline_data['total_duration']) * 100
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·éŸ³å£°é•·", f"{timeline_data['total_duration']:.1f}ç§’")
    with col2:
        st.metric("ç·ç™ºè©±æ™‚é–“", f"{total_speech_time:.1f}ç§’")
    with col3:
        st.metric("ç„¡éŸ³æ™‚é–“", f"{silence_time:.1f}ç§’")
    with col4:
        st.metric("ç„¡éŸ³å‰²åˆ", f"{silence_ratio:.1f}%")

def display_export_options():
    """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³"""
    st.subheader("ğŸ’¾ çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ“„ CSVå½¢å¼"):
            success, message = st.session_state.manual_segmentator.export_to_csv("manual_segmentation_results.csv")
            if success:
                st.success(message)
                with open("manual_segmentation_results.csv", "rb") as f:
                    st.download_button(
                        label="ğŸ“ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f.read(),
                        file_name="manual_segmentation_results.csv",
                        mime="text/csv"
                    )
            else:
                st.error(message)
    
    with col2:
        if st.button("ğŸ“„ JSONå½¢å¼"):
            success, message = st.session_state.manual_segmentator.export_to_json("manual_segmentation_results.json")
            if success:
                st.success(message)
                with open("manual_segmentation_results.json", "rb") as f:
                    st.download_button(
                        label="ğŸ“ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f.read(),
                        file_name="manual_segmentation_results.json",
                        mime="application/json"
                    )
            else:
                st.error(message)
    
    with col3:
        if st.button("ğŸ“„ SRTå­—å¹•"):
            success, message = st.session_state.manual_segmentator.export_to_srt("manual_segmentation_results.srt")
            if success:
                st.success(message)
                with open("manual_segmentation_results.srt", "rb") as f:
                    st.download_button(
                        label="ğŸ“ SRTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f.read(),
                        file_name="manual_segmentation_results.srt",
                        mime="text/plain"
                    )
            else:
                st.error(message)
    
    with col4:
        st.write("**ğŸ–¼ï¸ PNGç”»åƒ**")
        st.caption("ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç”»åƒã¨ã—ã¦ä¿å­˜")
        st.info("é–‹ç™ºäºˆå®š")


if __name__ == "__main__":
    main()