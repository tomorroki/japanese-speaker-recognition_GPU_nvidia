"""
æ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ  - Gradio UI
"""

import gradio as gr
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import os
import tempfile
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

from enhanced_speaker_recognition import JapaneseSpeakerRecognizer, RecognitionResult

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§recognizerã‚’ç®¡ç†
recognizer = None

def initialize_system():
    """ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    global recognizer
    
    try:
        # RecognizeråˆæœŸåŒ–
        recognizer = JapaneseSpeakerRecognizer()
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        if not recognizer.initialize_model():
            return "âŒ ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        # è©±è€…ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
        enrolled_count = recognizer.build_speaker_database()
        
        # èƒŒæ™¯ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        recognizer.build_background_model()
        
        return f"âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†ï¼{enrolled_count}åã®è©±è€…ã‚’ç™»éŒ²ã—ã¾ã—ãŸ"
        
    except Exception as e:
        return f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}"

def recognize_speaker_from_audio(
    audio_file, 
    show_jvs: bool = True, 
    show_cv: bool = False
) -> Tuple[str, str, str, str, str]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è©±è€…ã‚’è­˜åˆ¥
    
    Args:
        audio_file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        show_jvs: JVSè©±è€…ã‚’çµæœã«è¡¨ç¤ºã™ã‚‹ã‹
        show_cv: Common Voiceè©±è€…ã‚’çµæœã«è¡¨ç¤ºã™ã‚‹ã‹
        
    Returns:
        çµæœã®ã‚¿ãƒ—ãƒ« (ãƒ¡ã‚¤ãƒ³çµæœ, è©³ç´°æƒ…å ±, ãƒˆãƒƒãƒ—10ãƒ†ãƒ¼ãƒ–ãƒ«, ã‚°ãƒ©ãƒ•HTML, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹)
    """
    global recognizer
    
    if recognizer is None:
        return "âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“", "", "", "", "error"
    
    if audio_file is None:
        return "ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", "", "", "", "info"
    
    try:
        # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
        result = recognizer.recognize_speaker(audio_file)
        
        if result is None:
            return "âŒ è©±è€…è­˜åˆ¥ã«å¤±æ•—ã—ã¾ã—ãŸ", "", "", "", "error"
        
        # è¡¨ç¤ºè¨­å®šã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if result.all_scores:
            filtered_scores = recognizer.filter_scores_for_display(
                result.all_scores, show_jvs, show_cv
            )
        else:
            filtered_scores = {}
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®æœ€ä¸Šä½è©±è€…ã‚’æ±ºå®š
        display_speaker = result.speaker_id
        display_confidence = result.confidence
        display_raw_score = result.raw_score
        
        if filtered_scores:
            filtered_best_speaker = max(filtered_scores, key=filtered_scores.get)
            filtered_best_score = filtered_scores[filtered_best_speaker]
            
            # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®æœ€ä¸Šä½è©±è€…ãŒé™¤å¤–ã•ã‚Œã‚‹å ´åˆ
            if filtered_best_speaker != result.speaker_id:
                is_original_jvs = recognizer.dataset_manager.is_jvs_speaker(result.speaker_id)
                is_original_cv = recognizer.dataset_manager.is_common_voice_speaker(result.speaker_id)
                
                if (is_original_jvs and not show_jvs) or (is_original_cv and not show_cv):
                    display_speaker = filtered_best_speaker
                    display_raw_score = filtered_best_score
                    display_confidence = filtered_best_score
        
        # ãƒ¡ã‚¤ãƒ³çµæœã®ç”Ÿæˆ
        threshold = recognizer.threshold
        confidence_emoji = "ğŸŸ¢" if display_confidence > 0.5 else "ğŸŸ¡" if display_confidence > 0.25 else "ğŸ”´"
        threshold_status = "âœ… é–¾å€¤ã‚’ä¸Šå›ã‚Šã¾ã—ãŸ" if display_confidence > threshold else "âš ï¸ é–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ"
        
        main_result = f"""
## ğŸ¯ è­˜åˆ¥çµæœ

**è­˜åˆ¥ã•ã‚ŒãŸè©±è€…**: `{display_speaker}`  
**ä¿¡é ¼åº¦**: {confidence_emoji} `{display_confidence:.3f}`  
**ç”Ÿã‚¹ã‚³ã‚¢**: `{display_raw_score:.3f}`  
**é–¾å€¤åˆ¤å®š**: {threshold_status} (é–¾å€¤: {threshold:.3f})
        """
        
        # è©³ç´°æƒ…å ±
        detail_info = f"""
### ğŸ“Š è©³ç´°æƒ…å ±

- **å…ƒã®æœ€ä¸Šä½è©±è€…**: {result.speaker_id}
- **å…ƒã®ä¿¡é ¼åº¦**: {result.confidence:.3f}
- **æ­£è¦åŒ–ã‚¹ã‚³ã‚¢**: {f"{result.normalized_score:.3f}" if result.normalized_score is not None else 'N/A'}
- **ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨**: {'ã‚ã‚Š' if show_jvs != True or show_cv != False else 'ãªã—'}
        """
        
        # ãƒˆãƒƒãƒ—10ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç”Ÿæˆ
        if filtered_scores:
            # filter_scores_for_displayã¯æ—¢ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãªã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨
            # DataFrameã‚’ä½œæˆ
            df_data = []
            for i, (speaker_id, score) in enumerate(filtered_scores.items(), 1):
                df_data.append({
                    "é †ä½": i,
                    "è©±è€…ID": speaker_id,
                    "é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢": f"{score:.3f}",
                    "ã‚¿ã‚¤ãƒ—": get_speaker_type(speaker_id, recognizer)
                })
            
            df = pd.DataFrame(df_data)
            top10_table = df.to_html(index=False, escape=False, classes="gradio-table")
        else:
            top10_table = "<p>è¡¨ç¤ºã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“</p>"
        
        # ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆ
        chart_html = create_score_chart(filtered_scores, display_speaker)
        
        return main_result, detail_info, top10_table, chart_html, "success"
        
    except Exception as e:
        return f"âŒ è­˜åˆ¥ã‚¨ãƒ©ãƒ¼: {str(e)}", "", "", "", "error"

def get_speaker_type(speaker_id: str, recognizer) -> str:
    """è©±è€…ã®ã‚¿ã‚¤ãƒ—ã‚’å–å¾—"""
    if recognizer.dataset_manager.is_jvs_speaker(speaker_id):
        return "ğŸ—¾ JVS"
    elif recognizer.dataset_manager.is_common_voice_speaker(speaker_id):
        return "ğŸŒ CV"
    else:
        return "ğŸ‘¤ ã‚«ã‚¹ã‚¿ãƒ "

def create_score_chart(scores: Dict[str, float], best_speaker: str) -> str:
    """ã‚¹ã‚³ã‚¢ãƒãƒ£ãƒ¼ãƒˆã®HTMLç”Ÿæˆ"""
    if not scores:
        return "<p>ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“</p>"
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆfilter_scores_for_displayã‹ã‚‰æ—¢ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿ï¼‰
    speakers = list(scores.keys())
    score_values = list(scores.values())
    colors = ['#ff6b6b' if speaker == best_speaker else '#74c0fc' for speaker in speakers]
    
    # Plotlyã‚°ãƒ©ãƒ•ä½œæˆ
    fig = go.Figure(data=[
        go.Bar(
            y=speakers,
            x=score_values,
            orientation='h',
            marker_color=colors,
            text=[f"{score:.3f}" for score in score_values],
            textposition='auto'
        )
    ])
    
    fig.update_layout(
        title="è©±è€…åˆ¥é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ (Top 10)",
        xaxis_title="é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢",
        yaxis_title="è©±è€…ID",
        height=max(300, len(speakers) * 40),
        showlegend=False,
        template="plotly_white",
        yaxis=dict(autorange="reversed")  # ä¸Šä½ã‹ã‚‰ä¸‹ä½ã®é †ã§è¡¨ç¤º
    )
    
    return fig.to_html(include_plotlyjs='cdn')

def get_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—"""
    global recognizer
    
    if recognizer is None:
        return "ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        info = recognizer.get_system_info()
        
        system_info = f"""
### ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±

**ç™»éŒ²è©±è€…æ•°**: {info["enrolled_speakers"]}  
**ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ**: {info["sample_rate"]} Hz  
**èƒŒæ™¯ã‚µãƒ³ãƒ—ãƒ«æ•°**: {info["background_samples"]}  
**ã—ãã„å€¤**: {info["threshold"]:.3f}  
**ãƒ‡ãƒã‚¤ã‚¹**: {info["device"]}  
**ã‚¹ã‚³ã‚¢æ­£è¦åŒ–**: {'æœ‰åŠ¹' if info["score_normalization"] else 'ç„¡åŠ¹'}  
**ãƒ¢ãƒ‡ãƒ«**: {info["model_name"]}
        """
        
        return system_info
        
    except Exception as e:
        return f"ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"

# Gradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ§‹ç¯‰
with gr.Blocks(
    title="æ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ",
    theme=gr.themes.Soft(),
    css="""
    .gradio-table { margin: 10px 0; border-collapse: collapse; width: 100%; }
    .gradio-table th, .gradio-table td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    .gradio-table th { background-color: #f2f2f2; }
    """
) as demo:
    
    gr.Markdown("# ğŸ¤ æ—¥æœ¬èªè©±è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ")
    gr.Markdown("### SpeechBrain + ECAPA-TDNNã«ã‚ˆã‚‹é«˜ç²¾åº¦è©±è€…è­˜åˆ¥")
    
    with gr.Tab("ğŸ¤ è©±è€…è­˜åˆ¥"):
        with gr.Row():
            with gr.Column():
                # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                init_btn = gr.Button("ğŸš€ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–", variant="primary")
                init_status = gr.Textbox(label="åˆæœŸåŒ–çŠ¶æ³", interactive=False)
                
                gr.Markdown("---")
                
                # éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                audio_input = gr.Audio(
                    label="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    type="filepath",
                    format="wav"
                )
                
                # è¡¨ç¤ºè¨­å®š
                gr.Markdown("### ğŸ›ï¸ è¡¨ç¤ºè¨­å®š")
                show_jvs = gr.Checkbox(
                    label="ğŸ—¾ JVSè©±è€…ã‚’çµæœã«è¡¨ç¤º",
                    value=True,
                    info="èªè­˜çµæœã®ãƒˆãƒƒãƒ—10ã«JVSè©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
                )
                show_cv = gr.Checkbox(
                    label="ğŸŒ Common Voiceè©±è€…ã‚’çµæœã«è¡¨ç¤º",
                    value=False,
                    info="èªè­˜çµæœã®ãƒˆãƒƒãƒ—10ã«Common Voiceè©±è€…ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹"
                )
                
                # è­˜åˆ¥å®Ÿè¡Œ
                recognize_btn = gr.Button("ğŸ” è©±è€…è­˜åˆ¥é–‹å§‹", variant="primary")
        
        with gr.Column():
            # çµæœè¡¨ç¤º
            main_result = gr.Markdown(label="è­˜åˆ¥çµæœ")
            detail_info = gr.Markdown(label="è©³ç´°æƒ…å ±")
            
    with gr.Tab("ğŸ“Š ãƒˆãƒƒãƒ—10ãƒ©ãƒ³ã‚­ãƒ³ã‚°"):
        top10_table = gr.HTML(label="ãƒˆãƒƒãƒ—10è©±è€…ã‚¹ã‚³ã‚¢")
        score_chart = gr.HTML(label="ã‚¹ã‚³ã‚¢ã‚°ãƒ©ãƒ•")
    
    with gr.Tab("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"):
        system_info_btn = gr.Button("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’æ›´æ–°", variant="secondary")
        system_info_display = gr.Markdown(label="ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
    init_btn.click(
        fn=initialize_system,
        outputs=init_status
    )
    
    recognize_btn.click(
        fn=recognize_speaker_from_audio,
        inputs=[audio_input, show_jvs, show_cv],
        outputs=[main_result, detail_info, top10_table, score_chart]
    )
    
    system_info_btn.click(
        fn=get_system_info,
        outputs=system_info_display
    )

if __name__ == "__main__":
    demo.launch(
        server_name="localhost",
        server_port=7865,
        share=False,
        show_error=True,
        inbrowser=True
    )